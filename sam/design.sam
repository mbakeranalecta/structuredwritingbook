!smart-quotes: on
chapter:(#chapter.design) System design

    <<<(annotations.sam)
    
    index:: type, term
        task, system design 
        
   
    Unless you are writing directly on paper, chiseling into stone, or drawing letters by hand in a paint program, you are using structured writing techniques to create content. You are using tools that have been designed to partition and distribute part of the complexity of content creation in some way, and you are observing a discipline -- a set of constraints -- imposed by that partitioning. It is not a matter of whether your system is structured or not, but how and for what purpose it is structured and whether that purpose is being achieved.
    
    Therefore, the question you need to address is whether your current partitioning ensures that all of the complexity in your process is  directed to a person or process with the skills, resources, and time required to handle that complexity. Or is complexity going unhandled in your system and compromising efficiency and rhetorical quality?

    If this complexity is not appropriately handled, your rhetoric will be compromised and your customer satisfaction and bottom line will suffer. At that point, the question becomes, how do you change your approach to structured writing to handle complexity better?
    
    Do not approach this problem piecemeal. Complexity cannot be destroyed -- it can only be redirected -- and every tool you adopt introduces new complexity, which must also be partitioned and redirected. Attacking one piece of complexity in isolation directs that complexity away from the area you attacked, but that complexity goes somewhere, and if you don't think about where it goes and how it will be handled, you can easily end up with more unhandled complexity in your system than you started with.
    
    Because structured writing has the ability to move the complexity around the system, imposing it on one role at the expense of another can lead to piecemeal rather than comprehensive solutions as different groups or different interests try to attack their part of the problem. For instance, there is a long history of IT departments choosing content management systems because they were easy for the IT department to install and administer, only to have those systems become deeply unpopular because they pushed complexity out to writers and other users. On the other hand, some groups of writers want to write in uber-simple formats, such as Markdown, despite the difficulties that the limited structure and capabilities of those formats create for the overall publishing process. Each group tries to simplify its own work, heedless of the expense to others.     
    
    Here is the inescapable fact: complexity is irreducible. It can be moved but it cannot be destroyed. The only way to remove complexity from a process is to stop doing something. Therefore, the first question you should ask is: what you are doing that you should simply stop doing? What is not creating any value?

    But let's assume that you have done that. Once you've stopped doing things that don't need to be done, simplifying a function in one part of your process will always move complexity somewhere else in the system. Moving complexity somewhere else in the system is fine as long as you hand that complexity to an appropriate person or algorithm. The point is not to eliminate complexity, but to make sure it is handled correctly. The enemy is not complexity, it is unhandled complexity.

    How do you design a content system that ensures that as much complexity as possible is handled by a person or algorithm that has the time, skills, and resources to handle it? You start by understanding the sources of complexity in your content system. 
    
    section: Identifying complexity  
    
        Where is the complexity in your content system? It is different for every organization. Although the basic functions of content development are the same for everyone, the amount of complexity these functions generate differs greatly, depending on your needs and circumstances. For example, if you translate content into 35 languages, translation will generate more complexity in your content system than it will in the system of an organization that doesn't translate or translates into just one language. If you have a complex product line in an industry with a complex vocabulary, terminology control will create far more complexity in your system than for an organization with a simple consumer product. To partition and redirect complexity effectively, you need to identify the biggest sources of complexity in your content system. Here are some places to look:
        
        section: Current pain points 
        
            Inconsistency, duplication, delay, error, and failure are escape valves for unhandled complexity. The complexity underlying these problems can be difficult to see, even when it is causing pain. Familiarity with your current processes may make it difficult to see that things could be different. Seeing that there are alternatives often provides the insight into the hidden complexity of the current process. Hopefully the chapters in this book on the structured writing algorithms will help you see your current processes in a different light and, therefore, help you to identify the complexity in them and assess whether it is being adequately handled. 
            
            However, to find the sources of complexity, you may have to work your way upstream from where the problem is manifest. Ultimately, all unhandled complexity finds its way to your readers, so quality problems are the most common symptom of unhandled complexity. You may also see the impact of unhandled complexity in processes that seem too expensive or staff that seem overburdened or burnt out. 
            
            Let's say that you observe a rhetorical problem: readers are getting lost in the content. They find an initial page, but when they search for more information on the concepts it mentions, they end up back at the same page. What is the root cause of this problem? It could be one of (at least) three things:

            |Incomplete information| The information should be on the page, but it isn't. In this case, the unhandled complexity is in determining the readers' needs and making sure that needed information is present. You have a {repeatability} problem. 

            |Missing information| The information is not available anywhere in the content set. In this case, the unhandled complexity is in content planning. You may need to improve your audit capability.

            |Inaccessible information| The information is in the content set, but there is no link to it. In this case, the unhandled complexity is in managing and expressing relationships between subjects. If writers are unaware of these relationships, you may have a rhetorical-structure problem. If they are aware, then the cost of creating and maintaining links may be too high, leading them to skimp on linking. You may need a different approach to {linking}.
            
            When you do this analysis, be careful to avoid these two common pitfalls: 
            
            * Don't stop your analysis too soon, and don't be blinded by the limits of your current process. Trace the problem back to the actual source of complexity, independent of any tool or process considerations.
            
            * Don't stop with the first big chunk of complexity you find and rush off to buy a tool to address it. You need to identify all the sources of complexity in your system and come up with a comprehensive plan to manage them. Otherwise, you just move complexity around, while adding tool complexity to the mix. You could easily end up worse off. Even your biggest hot-button issues may demand a different solution after you have assessed all of the complexity in your system and created an overall plan to partition and direct that complexity.
            
        section: Unrealized possibilities
        
            Chances are that there are things you don't do today because they are not possible with your current tools, or any of the tools you are aware of. It is easy to overlook these unrealized possibilities because everyone else is dealing with the same limitations, meaning you may not see those possibilities implemented elsewhere. But don't allow your designs to be limited by what your current tools can execute.

            A comprehensive bottom-up linking strategy is a good example. If you are working in the document domain -- using document-domain or management-domain linking techniques -- creating, managing, and updating links is expensive and complex. That complexity leads writers to minimize the links they create or create them in sub-optimal places. That complexity manifests itself as unrealized potential. 

            However, if you switch to {subject-domain} linking based on {subject annotations}, you partition and distribute the complexity of linking away from writers and towards an algorithm. This radically reduces the barriers to a comprehensive linking strategy, making such a strategy possible. And you don't need a full {subject-domain} system to use this approach. It works just as well if you add subject annotations to otherwise {document-domain} information types.           
        
        section: What's working now
        
            Some parts of your current system are working well, successfully partitioning and directing complexity to the right people or processes. However, you still need to inventory this complexity to make sure it will still be handled well in your new process. Also, even if you are satisfied with parts of your current process, don't assume that those parts work optimally -- you may just be settling for what you are used to.
            
            For instance, if you currently handle complex tasks with an algorithm -- for example, you generate reference information from source code using {Doxygen} -- make sure you add those tasks and solutions to your inventory so that when you design your new system, you still handle that complexity properly. 
            
            At the same time, look around the edges of your current success stories for any unrealized potential. For example, if your generated references are published through a separate tool chain that makes them look different from, and not link to, the rest of your content, the unhandled integration complexity will compromise your rhetoric.

            Even if some of your current processes handle complexity well, you may need to change the way they distribute complexity in order to better manage complexity in your overall environment.  Don't lose sight of complexity just because you are currently handling it well.
            
        section: Complexity that affects others
        
            More difficult to identify are points where the impact of complexity falls on someone else. You don't feel that pain, because someone else is suffering the consequences. Often this is your readers, but it could be others in your organization -- support, sales, field engineering, etc. 
            
            For instance, if you ask developers to contribute content to your documentation set, but you are working in a complex document-domain or media-domain tool that they don't have the bandwidth to learn, you could be dumping a lot of authoring complexity on them. 
            
            You may get push back from the developers, saying that they are only willing to contribute content in a simplified markup language, such as {Markdown}. This simply deflects complexity onto someone else, since such languages may not give writers the structure and metadata they need to integrate the content with your publishing system. 
            
            Here you have a {functional lucidity} problem. The complexity of integrating content into your content set is not sufficiently partitioned and directed away from the occasional contributor. Chances are there is also a {rhetorical} problem here: developers may not know what information is needed, and they may not have received any rhetorical guidance. The solution may be to give them a {subject-domain} format that precisely specifies the content required. Developers may be willing to use this format (if its {functional lucidity} is good) precisely because it makes their lives easier by redirecting rhetorical complexity away from them. 
              
        section: Communication overhead 

            Any partitioning of a task creates communication overheads, because information has to be transferred between partitions. Communication overhead can be a huge source of complexity. Desktop publishing (DTP) was revolutionary in its day because it combined three jobs into one, eliminating communication overhead between writers, designers, and typesetters. This eliminated the communication overhead, but it made the writer's job much more complex. 

            When designing a system it is important to think about how much communication overhead your partitioning will create. In particular, consider how much {out-of-band communication} will be required to make your system work. Out-of-band communication means all the conversations and exchanges that are not captured in the content itself.

            For instance, in a {document-domain} content reuse scenario, the markup provides a way to include content, but writers still have to find the content. In addition, they may need to communicate with the person who creates and maintains the content to determine whether it is suitable for reuse and how it might change in the future. This is all out-of-band communication that is required to make reuse work. {Content management systems}(tool) and {workflow systems}(tool) are often used to manage out-of-band communication about content. 

            Organizations often place a lot of emphasis on improving collaboration by opening communication channels. However, opening communication channels is not the same thing as encouraging or facilitating out-of-band communication. Out-of-band communication, particularly around routine tasks is neither fruitful nor efficient. Instead, the real secret to effective collaboration is to improve your in-band communication, which improves productivity by reducing the need for constant meetings and emails.

            You can reduce the overhead created by out-of-band communication by placing more information in-band in your content and by designing your partitioning to avoid the need for a lot of out-of-band communication between partitions. For instance, with the {subject-domain} approach to {linking}, {subject annotations} contain in-band information about subjects mentioned in a document, making it possible for algorithms to find link targets at build time with a minimum of communication overhead among writers.
            
        section: Your style guide
            Traditionally, style guides have been a dumping ground for complexity. Every new rule and requirement created in response to a content problem gets written into an ever-growing style guide. Adding to the style guide does not handle complexity, it merely dumps complexity on writers. As the style guide grows, writers lose the capacity to remember or follow all of the rules and rhetoric suffers. 

            This does not mean you don't need a style guide. Some style issues cannot be effectively factored out, and writers need guidance to deal with those issues consistently. However, a writer's ability to conform to stylistic constraints is directly proportional to the number of such constraints. Using structured writing techniques to redirect as many style issues as possible away from the writer (and thus from the style guide) increases the conformance to those issues that cannot be partitioned or directed away by giving the writers less to remember.             
            
            A great way to inventory the complexities in your system is to go through your style guide looking for rules you could factor out by moving content to a different domain.
            
        section: Change management issues
            
            The growth in unhandled complexity is often interpreted (especially by the advocates of a system you have just installed) as a change management problem or a training problem. However, even though change management and training are both necessary any time you introduce a new system, design issues are the most likely cause of problems. In particular, problems often come from a system design that redirects complexity without considering where that complexity will land or how it will be handled. 
            
            Change management is a scapegoat for process complexity that no one will own. It is common to blame the failure of structured writing systems on writers being unwilling to change. The cure, the backers of the system assure us, is more training and more vigorous promotion of the system and its virtues. But the problem is more likely to be that the system design has dumped new and unmanageable complexity on whatever group is rebelling -- almost always the writers, either full-time writers or occasional contributors. 
            
        section: What's coming down the road      
        
            The world is in the middle of a transition from paper to hypertext.[*hypertext] This involves three types of complexity. First, the complexity of architecting information and publishing to paper. Second, the complexity of architecting information and publishing it to hypertext. Third, the complexity of transitioning your content processes from exclusively focusing on paper and paper equivalents (such as PDFs) to either publishing both or only hypertext.  
            
            footnote:(*hypertext)
                I say hypertext here rather than web because the web is both a delivery vehicle and an information architecture. You can publish to the web by sticking a PDF on a server. This is not hypertext. On the other hand, there are hypertext media that are not on the web, such as hypertext CD-ROMs or help systems. In terms of creating complexity, it is hypertext, not the web itself, that makes a difference. Hypertext requires a different approach to {rhetoric} and {information architecture} and requires major differences in the {linking} and {publishing} algorithms.

            Most organizations currently produce both paper and hypertext, but most are not doing both well. As noted in [#chapter.single-sourcing] and [#chapter.architecture], there are major differences in how you write, organize, present, and format content for paper and for hypertext, and differential single sourcing requires different tools and techniques than are found in most single sourcing tools today. Most tools allow you to design for one medium and then do a more-or-less best effort attempt to transfer that design to other media. 
            
            This means that in practice, whether you acknowledge it or not, you have a primary medium and a secondary medium. And while there are {differential single sourcing} techniques that can improve your ability to address each separately, there are limits to what you can do to address both without rewriting content to fit two different {information architectures}. In short, unless you plan to go web only (and some organizations are web only for a large part of their content), you have to choose a primary medium. 
            
            Shifting to a new primary or exclusive medium can remove some complexity from your system. {Reuse}, for instance, is a much bigger issue for print than for {hypertext}, where you can link to common material rather than including it inline. {Single sourcing}, and {differential single sourcing} in particular, are larger issues in the transition period than they will be if you stop producing paper formats. {Linking} and the techniques of a {bottom-up information architecture}, on the other hand, belong to the {hypertext} world and are likely to grow in importance as you turn more of your focus to the web and online media. 

            If you choose your tools and your structures primarily on the basis of the needs of the paper world or the transition period, you are likely to find yourself going through a similar upheaval in just a few years when the transition to {hypertext} catches up with you.  
     
    section: Partitioning and directing complexity
    
        Once you have identified your major sources of complexity and have a good understanding of what that complexity costs you in terms of process and quality, it is time to decide how to partition and divide that complexity and to choose the structured writing techniques you will use to achieve that partitioning. 

        In some cases, you can reduce the complexity that falls on each individual in a group by taking a complex operation away from the group and distributing it to one uniquely qualified person. For example, when you {separate content from formatting}, you take formatting responsibility away from all writers and distribute it to a single designer who writes the {formatting algorithm}.

        In other cases, you can take a complex operation currently being performed by a single person and distribute it out to many contributors. For example, {linking} is typically the sole responsibility of the person writing the piece that contains the links. But the {subject-domain} approach to linking, which uses {subject annotation} rather than link markup, partitions and distributes the linking task in three ways. Writers identify significant subjects in their text, other writers index or structure their content so that its subject matter can be identified clearly by algorithms, and an {information architect} or {content engineer} writes the algorithm that handles either {linking} or some other method of handling {subject affinities}. In another example, the bottom-up approach to {terminology} management partitions and distributes the task of terminology discovery to writers while distributing terminology management to a {terminologist}. 

        section: Partitioning the writing task
        
            As is no doubt clear by now, I regard the heart of this process to be partitioning and directing complexity away from writers. Writers are the principle source of value in your content process. Writing requires full attention, so any complexity that writers have to deal with diminishes the attention they have available for writing, which always compromises rhetoric and content quality. Achieving {functional lucidity} for writers should be the first priority of your content system design. 
        
            Because attention is a limited resource, there is value in partitioning and distributing tasks even when you perform all of the tasks yourself. Partitioning tasks allows you to give your full attention to each individual task and, thus, perform better than you would if you tried to divide your attention between multiple tasks at the same time.

            But {functional lucidity} is neither fixed nor universal. It depends on each writer's background and skill set. It also depends, to some extent, on the nature of the writing task. Functional lucidity for creating entries in a reference is different from functional lucidity for creating a slide deck or an essay on the architecture of a product. For any activity, familiarity and frequent practice reduce the amount of attention required to do it well. Thus, a full-time professional technical writer should be able to handle more content management responsibility and need less rhetorical guidance than an occasional contributor. On the other hand, a full-time writer might need more rhetorical guidance than a subject matter expert to create highly technical material, because the writer may not understand the technology or the reader's task as well. However, no matter how much complexity they can handle, writers will always benefit from a system that maximizes {functional lucidity} and partitions complexity appropriately.

            That said, there are times when you should direct complexity toward writers. As we saw when we looked at {terminology} management, writers understand how terminology is being used and what subjects your terminology needs to cover. A terminologist, however skilled, has less of this day-to-day knowledge and may miss subtleties that need to be expressed or be unaware of local terms that would communicate those subtleties most effectively to a particular audience. {Subject annotation} partitions terminology discovery towards writers without adding any complexity, as long as they are already creating {subject annotations} for other reasons. And it partitions conformance checking and decision making towards the {terminologist}.          

        section: Partition towards expertise
        
            A good principle is to always partition and direct complexity towards expertise. If expertise is distributed, direct complexity outwards. If expertise is centralized, direct complexity inwards. For example, bottom-up terminology management partitions language choices towards writers -- who understand the context for the terms they use -- while allowing discovery and conformance to flow back to {terminologists} -- who have the skills to look at the broader issues of conformance across the content set. 

            In many cases, you want to direct complexity to algorithms. To do this, you need to clarify the rules that an algorithm must follow, partitioning complexity between processes that follow consistent rules and, therefore, can be handled by an algorithm and processes that require human attention.
        
            Using {subject-domain} annotations to drive linking is a good example of this. Finding a resource to link to for every significant subject mentioned in a content set is complex and tedious. The task becomes even harder when content changes all the time and has to be continuously published. Even so, the basic rules for link discovery are consistent. Where subject X is mentioned, create a link to the best resource or resources on subject X. The problem is identification. How do you identify subjects that are worth linking to and how do you identify the best resources for those subjects? 
        
            Forming links by hand is complex and time consuming. However, if you annotate subjects and index topics by subject, you can provide algorithms with the information they need to create links accurately. But there is a wrinkle to this. If you don't control the {terminology} you use to talk about significant subjects, simply naming the subjects might not be enough for an algorithm. Inconsistent or ambiguous names can cause an algorithm to misidentify subjects and topics. Adding type information to {subject annotations} (such as identifying _Rio Bravo_ as a reference to a movie) removes the ambiguity and lays the groundwork for appropriate {terminology management}. This is a complicated piece of complexity management and partitioning, but it allows you to remove a lot of complexity from writers while greatly improving {linking}, {change management}, and {terminology management}.           
        
        section: Focus on complexity, not effort    
            
            Complexity is by no means the same thing as effort. Well-designed structured writing systems that support appropriate algorithms can reduce overall effort and significantly improve quality. However where you place complexity matters. Even if a task requires less effort, adding complexity changes how those assigned to the task work and how they need to be qualified and trained. It is important to appreciate how the distribution of complexity and effort affects the dynamics and composition of your team. 

            For example, managing {links} using keys, as described in [#chapter.linking], makes it easier to change link targets in {reuse} scenarios, compared to editing links by hand. However, creating links in the first place is much more complex, requiring more knowledge and skill. By contrast, managing linking using the {subject-domain} method of {subject annotations} (described in the same chapter) reduces both complexity and effort for writers, but it distributes more complexity to the processing system and those who maintain it. Each method for managing links -- by hand, by keys, or by subject annotations -- represents a different distribution of effort and complexity. 
            
            In the end, the question of where you distribute complexity in your system is at least as important as the question of how much effort you avoid. The wrong distribution of complexity compromises quality by undermining both the productivity of those saddled with misplaced complexity and the reliability of your algorithms. Not only does badly distributed complexity compromise quality, it also undermines cost saving efforts.
            
            Distributing complexity away from writers is key because when a structured writing system distributes complexity towards writers, it doesn't merely add a new and complex task, it imposes that complexity directly on the activity of writing itself. Giving writers more complexity than they can handle not only affects the quality of their content, it also affects the correctness of the structures they create. Algorithms that reduce effort rely on accurate structures. If overloaded writers create poor content structures, algorithms cannot work properly, which will result in even more effort spent fixing problems.

            You will probably achieve a greater reduction in effort by focusing on partitioning complexity rather than attempting to reduce effort directly. Indeed, it is sometimes worth investing in activities that seem like additional effort -- for example, creating structures and algorithms to improve repeatability and conformance or creating specific {subject-domain} structures for a new subject -- instead of knocking out content in a generic document-domain format. Avoiding up-front effort may seem like a win, but in many cases, the down-stream effort created by less reliable content and algorithms will be far greater.        

        section: Indivisible complexity    
                    
            There are complex tasks which by their very nature have to be done by one mind. It is important to respect this indivisible complexity when planning your content system. Splitting functions that belong together, such as writing semantic blocks and combining them into sound readable rhetorical blocks, can cause severe quality problems. Remember that partitioning complexity always requires you to create a structure that transmits all of the information required for the next partition to do its job. If there is too much required information to be passed, or if the required information can't be easily expressed in a standard way, then you haven't reduced the complexity of the first partition sufficiently, and complexity will fall through the cracks. That which cannot be cleanly partitioned should be kept together.
            
        section: Subtract current tool complexity
        
            All tools introduce complexity into the content system. We choose them because they allow us to partition and distribute complexity better, including their own complexity. But when you are inventorying the complexity of your system, the complexity introduced by your current tools should not be part of the inventory. Those tools may be going away as a result of your system redesign, so their complexity should not be part of the inventory of complexity in your content system.
            

        section: Avoid tool filters 
        
            When you design a process, it is important not to see things through the filter of your current tools. Every tool reflects its designer's view of how the complexity of the content system should be partitioned and directed. Thus, because the way you partition and direct complexity defines your process, every tool encapsulates a process. When you buy a tool, you buy the process it encapsulates. Long practice with a tool shapes how you view process, and, after a while, it is hard to imagine a process in any other terms. 
            
            Thus, all too often when we write the specifications for a new tool, we essentially end up asking for our old tool with some particular improvement we think will make our lives better. But often, the improvement we are seeking is not compatible with the current tool. (If it were, the vendor would probably have included it in their ongoing attempts to drive upgrade sales through new features.) If your old tool won't cut it, chances are you need a different process from the one incorporated in that tool, and you need to break through your tool filter to envision a new process. That is why this book has focused on algorithms and structures rather than tools and systems -- to help you overcome the tool filter in your process design decisions.

            Over the years I have seen many requirements documents for proposed structured writing systems that essentially said that the proposed system must work exactly like {Microsoft Word}. This is not surprising when the people writing the requirements have used nothing but Word to create content for years. The tools you know shape how you work and what you think of as possible. As {Henry Ford} is supposed to have said about the Model T, "If I asked customers what they wanted, they would have said faster horses." Even when we are dissatisfied with our current tools, we tend to want the same basic tool only more so. That is why so many structured writing tool vendors advertise that their editor looks and feels "just like Microsoft Word" and why some vendors create tools that modify Word itself.

            But {Microsoft Word} sits on the boundary between the {media}(concept "media domain") and {document domain}s. Using Word, or something that looks like Word, for structured writing is usually an attempt to move writers a little bit further into the {document domain} without disrupting their familiar work environment. But the {WYSIWYG} authoring interface invites writers to slide back into the {media domain} by hiding structure and showing only formatting, which should be factored out in the document domain. 

            It is not surprising, then, that the most popular structured writing tools to date predominantly use document-domain structures that  are, like {DocBook}, very loosely constrained. It is much easier to write an {XML} document in a {WYSIWYG} editor if the underlying structures are minimally constrained, since you can insert whatever bit of formatting you want anywhere you want, just as you can with {Word}. Even {DITA} -- which, while fundamentally in the {document domain}, is more constrained and capable of being constrained further -- tends to be used in its generic out-of-the-box form with tools that provide a Word-like {WYSIWYG} interface. 

            Thus even when the decision-making process is based on business requirements rather that specific tools, it is often tacitly driven by existing tool sets and ways of doing things, because those existing tools and processes shape our view of what the business requirements actually are. We don't ask for a better way to get from Des Moines to Albuquerque, we ask for a faster horse that eats fewer oats. This is why it is important to forget about your current tools and their associated processes and focus on the sources of complexity in your system and how you can partition and distribute that complexity effectively.   
    
    section: Selecting domains

        Once you have a good idea of where the complexity lies in your content system and how you would like to partition and direct that complexity, it is time to decide which domains you want to work in. This is not as simple as picking one of the three and using it for everything. There are some pieces of content for which no meaningful {subject-domain} markup makes sense -- for example, content that has no repeatable pattern of either subject matter or rhetoric. For such content you need generic markup in the document or {media domain}. Some content needs to be laid out by hand with an artist's eye for design. That can only happen in the media domain. In practice, your content system is likely to include a mix of subject-domain, {document-domain}, and media-domain content, with some measure of the {management domain} thrown in where needed. In fact, major public languages like {DITA} and {DocBook} contain structures from all four domains. 
        
        Also, the places where complexity is hurting your content are not necessarily the same for all content types. The complexities that attend the maintenance of a reference work are likely to be different from those that attend the creation of a full-color print ad in five languages. Different types of content require different partitioning and direction of complexity and, therefore, require different structures from different domains. 
        
        In an ideal world, the choice of domains would be simple. Given the complexities you have identified for partitioning and redirection, choose the domain that accomplishes the desired partitioning. But, in practice, it is more complicated because structures and the algorithms that process them are themselves sources of complexity.

        For example, {DITA} may address the complexities of {content reuse}, but it also introduces complexities into the writing process in the form of complex markup and {management-domain} intrusions. DITA also introduces significant {content management} complexity, both because it produces so many small artifacts and because writers need a way to find reusable content. This creates a retrieval problem, which creates terminology management complexity. Handing these new complexities requires new tools, typically a {DITA}-aware {structured editor} and a DITA-aware {component content management system}(tool), along with new roles and extensive training. And even with those things in place, writers must deal with a lot of conceptual and management complexity. And you still have issues with rhetorical conformance because there is no way to constrain {rhetorical blocks} larger than a DITA topic. 
        
        All of that additional complexity, and the cost of the tools, may be worth it if you can realize big enough gains from {reuse} without falling into its quality traps. For many organizations, the savings from reduced {translation} costs swing the needle to the positive side rather than any benefits from reuse alone. But some organizations have reported that they simply don't realize the amount of reuse that would justify the expense and complexity of their {DITA} systems. 
        
        {DITA} provides every document- and management-domain {reuse} algorithm in the book, but at a high cost in additional introduced complexity. You might find you are better off with either a reuse system that doesn't impose the kind of information typing constraints that are fundamental to DITA or a simple {document-domain} system that provides a less comprehensive suite of reuse features but injects less complexity into your process. Or you might be better off with {subject-domain} reuse tactics that are less comprehensive than DITA-aware document- and management- domain tools but which actually remove complexity from the writer rather than adding it, improving both {functional lucidity} and {conformance}. It is usually better to optimize the overall management of complexity across your entire system rather than to optimize one function at the expense of others.  

        Another source of complexity to consider when you choose domains is the amount of in-house development needed to implement them. {Media-domain} tools such as {FrameMaker} or public {document-domain} tools, such as those that support {DocBook} and off-the-shelf {DITA}, all come with ready-made structures and algorithms. To implement a {subject-domain} strategy for your own content, you have to develop some structures and algorithms yourself. This obviously adds a level of complexity to your process. 
        
        However, even with {media-domain} and public {document-domain} tools, you will almost certainly have to do some structure and algorithm development, probably on an ongoing basis. Developing and maintaining {FrameMaker} style sheets is structure and algorithm development, and supporting tools such as {FrameScript} transfer mundane formatting or management tasks from writers to algorithms but require effort to develop those algorithms. If you want your DITA or DocBook output to match your brand, you need to develop {formatting algorithms} or modify the existing style sheets to create the look you want. And if you do any kind of {DITA} {specialization} or {DocBook} customization, you will need the same development skills that would you would need to develop your own {subject-domain} structures and algorithms.
        
        As we have seen throughout this book, the {subject domain} provides the most comprehensive set of structures and algorithms for addressing structured writing requirements. In particular, it does the best job of partitioning and directing complexity away from writers, which potentially opens your system up to a wider range of contributors. It also provides for higher levels of conformance, which in turn means more reliable algorithms. And with the {subject domain}, most algorithms work on the same set of structures, as opposed to the {document}(concept "document domain") and {management domains}, where each algorithm requires new structures. Finally, while there are more of them, subject-domain structures tend to be small with few permutations of structure, meaning that their algorithms have less complexity to handle. All this helps contain development complexity. 

        Nonetheless, even if you identify the {subject domain} as the best way to create the bottom-up information architecture you want, you might decide that writing and maintaining the necessary structures and algorithms introduces too much complexity. In that case, you might be better off with a solution based on a {wiki} or a simplified markup language such as {Markdown}. This would throw more of the responsibility for {linking} and {repeatability} onto writers, but that might be the right balance to strike in how complexity is partitioned and directed in your organization. Scale can play a big role in this decision. At a large scale, managing linking and repeatability by hand becomes onerous, while developing and maintaining {subject-domain} structures is amortized over a larger body of content.  

        We can usefully map the various content management domains in terms of two properties: complexity and diversity. Complexity measures the size of a language and its level of abstraction. Diversity measures the number of different languages required to represent a set of content (see [*fig.domain-map]).

        figure:(*fig.domain-map) Diversity and complexity of markup languages in the three domains
            >>>(image ../graphics/domainmap.xml)
        
        As you can see in [*fig.domain-map], the well-known {document-domain} markup languages, such as  {DITA} and {DocBook}, are by far the most complex, especially when they are used out of the box with no customization. Complexity is not merely a matter of the number of elements in a schema. It is also a matter of the number of different combinations or permutations of those elements that are allowed. If, as is common, a schema allows writers to insert any one of dozens of different elements into many different places in a document, then they have to understand the possible permutations and their consequences. And {information architects} and {content engineers} must anticipate and handle all those permutations in the algorithms they write.

        Because of their size and loose structure, there is little you cannot express in these languages, but they are also a huge source of complexity that can be difficult to partition and redirect successfully. Simpler document-domain languages are less complex but also less capable. Some document designs simply cannot be expressed in {Markdown} or similar languages.
        
        However, the upside of the document domain is that it is very homogeneous. You can express nearly any document design using {DocBook} or out-of-the-box {DITA}. This does not mean that these languages support an efficient partitioning and redirecting of content system complexity; it simply means that you can use either one of these languages to produce nearly anything other than layout-specific designs (which require the {media domain}). This is obviously appealing because you need only a single tool set and a single set of training. No matter how complicated the tools and the training may be or how much those complications limit participation by occasional contributors, at least you have only one thing to worry about. 

        The {media domain}, by contrast, is both moderately complex and moderately diverse. At the core of its diversity is the paper/hypertext divide. But there are multiple forms of paper (including virtual ones such as e-books) and multiple forms of online media, which adds to its complexity. The initial motivation for most structured writing, {separating content from formatting}, was to tackle the challenge of publishing in diverse media.

        The move away from the media domain accelerated as we entered the transition between paper and the hypertext. Prior to the beginning of this shift, most organizations delivered only to paper and, therefore, could work in the {media domain} without problems. However, they could not take advantage of structure and algorithms in handling the rhetoric and process of the content system.

        While there is no sign that paper or paper-like electronic media are going away entirely, we have reached the point where more and more content is created and delivered only on the web. Thus, media-domain tools, and simple document-domain tools like {Markdown} that are specific to the presentation needs of one medium, are gaining in popularity. Again, the use of the media domain cuts you off from the assistance of algorithms in performing the synthesis. This means you can't use structure to constrain your rhetoric or algorithms to check your conformance and you can't vary your presentation for different audiences or media, since these things happen in the subject and document domains. However, because so much information delivery is once again targeted at a single medium, the media domain is becoming increasingly viable.

        The {subject domain} is far less complex than the {media domain} or the {document domain}. Our recipe markup is less complex than even {Markdown}. But the subject domain is far more diverse. There are hundreds of different subjects, each with its own unique structure. And presenting the same subject to different audiences may require a different subject-domain structure to capture a different rhetoric. Obviously, you don't need all the subject-domain structures in the world. You only need enough to cover your subject matter for your audience, but that is still be more than you will need if you chose to write in the document domain or the media domain. 

        On the other hand, most {subject-domain} structures are simple. That does not necessarily mean that they have a small number of elements, though that is almost always the case. But it does mean that there are few permutations of those elements, which makes it easier to validate and process subject-domain content. Because subject structures are concrete rather than abstract and because they use the language of the subject matter, they tend to be clear and intuitive to writers. Writers need little or no training to use them. And subject-domain structures can often be expressed in lightweight syntax, removing the need for expensive editing software. 

        However, the diversity of structures is itself a source of complexity. You can't buy subject-domain structures and algorithms off the shelf. You have to create and maintain them yourself. This does not mean you have to maintain a complete custom publishing tools chain. You only have to manage the processing from {subject domain} to {document domain}. You can make any existing {document-domain} language your {document-domain} layer and use its tool chain for the rest of your publishing system. By extension, if you already have a {document-domain} system in place, you can add a {subject-domain} layer on top of it without changing the rest of your system.

        Creating and maintaining subject-domain structures and algorithms is relatively simple, because the structures themselves are simple and well constrained with few permutations. It is also made significantly simpler because most structured writing algorithms are supported by the same {subject-domain} structures, unlike the document and management domains, where each algorithm requires a different structure.

        For instance, subject annotations can be used for linking, presentation, auditing, and terminology management, whereas link markup in the document domain is useful for link management alone. And because it has good functional lucidity, the {subject domain} tends to produce more reliable structures, so there are fewer error conditions to worry about. With an architecture that partitions the publishing process well, there should be few side effects.
        
        However, you will need to add new structures and algorithms from time to time, and you will need to work rapidly. This means that you need to keep {information architecture} and {content engineering} skills available to your organization. Although this is definitely a source of complexity in a {subject-domain} system, it is not as onerous as it sounds, and any large {document-domain} system will also require these skills.

        Ultimately, then, there is no one right domain that everyone should be working in, and certainly there is no one right tool that everyone should be using for content creation. Rather, each of the three (plus one) domains of structured writing offers different capabilities for partitioning and directing the irreducible complexity of the content system. Which you choose should ultimately depend on the nature and type of complexity you are dealing with and the resources available to address that complexity. None of the structured writing domains are destinations, and none are desirable in themselves. They are merely means to an end: a content system in which all of the complexity of content creation is handled by a person or process with the appropriate skills, time, and resources to handle it, resulting in efficient process and effective rhetoric.        
            
    section: Selecting tools
    
        Once you have decided how to distribute complexity in your content system, you need to choose the languages, systems, and tools that will allow you to implement that partitioning most efficiently. This may be a recursive process, since tools introduce complexity of their own that must be partitioned and distributed to make sure each tool does not introduce unhandled complexity. As you begin to select tools for your system, pause to consider how the complexity that each tool introduces will be handled. This may require changing other procedures or introducing other tools. If a tool introduces too much downstream complexity or the complexity it introduces is too hard to handle, you might need to consider a different tool or even a different strategy.
    
        It is a simple fact of life that as you move content from the media domain towards the document and subject domains, the number of available off-the-shelf tools becomes fewer and the need to configure or extend those tools to get the result you need becomes greater. The reason for this is simple. The further you move your content towards the subject domain, the more you must rely on context-dependent algorithms to move it back to the media domain for publishing. 
        
        This is, after all, the point of the exercise. You move functions from people to algorithms to ensure that the complexity of the content system is handled appropriately and efficiently. The objective is to produce better content in less time and at less cost, and that is accomplished by handing parts of the work over to algorithms. The further you go along the continuum from media domain to subject domain, the more particular the algorithms become to your organization, your audience, and your subject matter. Thus, you have to become more engaged with the design of algorithms and the structures they require.
        
        The need to take more responsibility for structures and algorithms is not a downside. It is what you are aiming for. You want to transfer effort and complexity from humans to algorithms, which means you need to transfer complexity to those who write algorithms. The need to employ people to write and maintain those algorithms is not a drawback. It is not that structured writing requires you to hire people to do these things. It is that partitioning some of the complexity of content creation away from writers and to content engineers and information architects requires that you adopt structured writing as a means to this end. Partitioning complexity better means dividing responsibilities among different specialists. Structured writing is merely the means used to achieve this distribution while meeting all of your rhetorical and technical requirements for output. 
   
        This should not be taken lightly. It is the point of the exercise and, therefore, needs to be taken seriously and approached deliberately. Developing this capability within your organization is far more important than your choice of tools or even domains. Understanding the capabilities you need in your organization comes back to how you partition the complexity of your system. Remember, the goal is to enhance rhetoric and process by partitioning and directing complexity so that every part of that complexity is handled by a person or algorithm with the skills, time, and resources to handle it.

        Once you decide what complexity you want to partition and direct away from your writers, you can identify the tasks your information architects and content engineers will need to handle. Quite simply, then, you are looking for people with the skills to handle those tasks, and you need to give them the time and resources they need to do the job. The roles and qualifications for these people will differ for each organization, since each organization faces different levels of complexity and will partition and distribute complexity differently.   

        As we have noted, most off the shelf content management systems and most public content formats tend towards the use of a single format for all content, usually using a combination of the document and management domains. I have explored the disadvantages of that model throughout this book. However, this does not mean that all such systems become ineligible for use in your content process. The use of a rich document domain format packaged with sophisticated publishing capabilities in multiple media can make perfect sense, as long as you are not boxed into using that format for all authoring. Such a system may perform very well as the middle part of your publishing system, with a separate subject-domain authoring layer which can feed content from many sources. (If you go this route, though, do remember to make adequate provision for {differential single sourcing} to all the media you need to support.)
           
    section: Counting the costs and savings   

        Most of what is written about structured writing focuses on cost savings, especially savings from content reuse. I have chosen, instead, to focus this book on managing complexity and enhancing rhetoric. Focusing on cost reduction, while it makes for an easy sell to those who must ultimately fund any structured writing project, often leads organizations to single out one particular cost, to the exclusion of other costs and opportunities. Organizations that fall into this trap often introduce complexity into their systems that eats up all of the anticipated savings while damaging the rhetoric of the content. 
        
        A focus on cost reduction also carries with it an implicit admission that you can't think of ways to enhance the value of what you do -- increasing value trumps reducing costs, and it has more upside. A focus on complexity, on the other hand, addresses both cost and quality at the same time. Unhandled complexity, or complexity handled by the wrong person or process, not only reduces quality, it also costs money. You may not be able to produce a neat (and misleading) spreadsheet that equates content reused with dollars saved, but a focus on comprehensive management of complexity can yield cost savings while enhancing value. 
        
        The economics of this decision are complex. You may decide that the cost of creating and maintaining the most appropriate algorithms and structures is not worth the cost or quality improvements they promise. But you should make that decision with a full appreciation of the benefits those algorithms are capable of delivering. Whatever you decide, make sure you understand how complexity is distributed in your system, make sure that the people you distribute complexity to have the skills, time, and resources to handle that complexity, and be conscious of the effect it will have on their productivity and the quality and reliability of their work.     
        
        Structured writing is a tool for managing the complexity of your content system and making sure all of that complexity gets handled by people with the right skills and resources. The ultimate objective is to enhance both process and rhetoric. Getting there may require your team to learn new skills, or it may require you to bring in staff with the needed skills. Don't regard bringing in those skills as a downside of structured writing. Instead, look at it as a method to better handle the complexity of content creation. Structured writing is simply the technique you use to partition and transfer complexity around your system so that everyone on the team can do their jobs better. 
