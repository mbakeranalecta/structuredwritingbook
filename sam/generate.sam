chapter:(#chapter.generated) Generated Content

    <<<(annotations.sam)

    index:: type, term
        concept, generated content 
        task, generating content

    I have mentioned at several times already that one of the advantages of the subject domain is that it allows you to generate different types of rhetoric from a base of subject domain data. Here I will look at the content generation algorithm in greater depth. 

    section: Categorization
        One of the key elements of top-down information architecture is {categorization}. An {information architect} develops categories of content and develops an organizational schema (such as a table of contents) based on those categories. This may include levels of subcategories forming a hierarchical categorization scheme.  
        
        Not all categorization is hierarchical, though. In some cases content can be classified on several independent axes, allowing for the development of what is called {faceted navigation}. The easiest place to see faceted navigation in action is on a used-car site where you can narrow down your selection using any set of criteria that matter to you, such as selecting blue convertibles or all-wheel drive vehicles with manual transmissions. 
        
        Categorization of content require metadata to identify which category it belongs to. (Even if you just sort papers into piles, as soon as you put a label on each pile, you are adding metadata, and if you don't add a label, you will soon forget which pile is which.) Categorization may involve the addition of new metadata or it may rely on existing metadata that is already attached to the content. This effectively means that your categories are expressed as query statements, and those queries do not have to operate on a single piece of metadata. They can create a category out of the conjunction of several pieces of metadata. For example, they can create a category of heart healthy recipes by looking at the salt, fat, and calorie metadata of a collection of recipes.  
        
        For content in the {subject domain}, therefore, the {metadata} required to assign a piece of content to a category may be inherent in its subject domain markup. It is the nature of the subject domain to describe the subject matter and any markup that describes the subject matter may already contain the fields that you need for categorization. This is one of the attractions of the subject domain: the markup can serve many purposes, which simplifies both markup design and content authoring and often means that you don't need to create additional structures to support a new algorithm.
        
        Relying on the {subject domain} {metadata} already in the content, rather than creating a separate metadata record, can be a tremendous advantage, because it makes submission of content to a {repository} so much easier for authors. But in some cases it can also avoid the need for a costly {content management system}, since it allows the {publishing algorithm} to categorize content at build time without the need of a separate metadata store or a separate system to manage categorization. I will look more at the role of the content management system in [#chapter.management-domain].
        
    section: Linking
    
        We have covered the {linking algorithm} already ([#chapter.linking]), but linking is at the heart of a bottom up information architecture. In a bottom-up architecture, a page is not simply a leaf on a tree: the prize you find at the end of the search. It is a junction point in the exploration of an information space and the quest to understand a subject. In reading a page, a reader may discover new subjects that they need to understand and new options that they need to consider ({subject affinities} in the content). They may discover that what they thought they knew is wrong, or what they thought they wanted to do was not the right choice. They may find that their search or their traversal of the categorization system has led them to the wrong place, or they may discover whole new worlds they wish to explore. At a more mundane level, they may discover that they need additional information to complete their task, such as reference data. 

        These are all pointers to some next topic that the reader needs. Even the most prescient writer cannot have chosen all of them as the linear next topic in a linear narrative. To serve the reader they need to pave all of these possible paths for them, and the way you do that is with {hypertext} {links}. 
        
        This means that linking is not something that happens at arbitrary points where the author feels like adding a link. It is something that is planned for as part of the {information architecture}. Whether you specify hard links in the {media domain} or the {document domain}, manage them with keys in the {management domain}, or generate them from {subject annotations} in the {subject domain}, they should be created in a disciplined and consistent manner according to a deliberate plan.  
    
    section: Tables of Contents
    
        {Tables of contents} can serve various purposes depending on the nature of the work. Some describe a linear reading order for a work, some provide a {classification} scheme for random access to the content, some are simply a list of chapters that does not necessarily imply an intended reading order. 
        
        A {table of contents} may seem like a {document domain} structure, but it is really more of a {media domain} structure, for two reasons. First, it contains specific links to specific resources at specific addresses, or specific page numbers in a paper or a virtual paper format such as {PDF}. Secondly, it is virtually always factored out in {document domain} {markup languages}. Tables of contents are not written, they are generated. 
        
        From an {information architecture} point of view, what matters is how they are generated. In {DocBook}, for instance, it is typical to write each chapter of a book in a separate `chapter` file and then pull them together into a book using a `book` file. The order of the table of contents is then determined by the order in which the chapters are listed in the `book` file. The TOC itself is generated by extracting chapter and section headings from the `chapter` files in the order they appear in the `book` file. 
        
        In {DITA}, the normal process is to assemble a book using a `map` file. A map file may assemble a book out of {DITA} topics or other maps, and this may include assembling the chapters from topics as well. In the end, though, the {table of contents} is generated in the same way, by traversing the document assembled by the `map`.
        
        In both these cases, the order of the TOC is specified by hand by the person who creates the `book` or `map` file. But there are other ways to determine the order of content in a TOC. For instance, a reference work such as an API reference may be organized by listing each library in order by name, and each function in alphabetical order by name within its library, creating a table of content with two levels. There is no need to write a map or book file to create this table of contents. There is an algorithm for creating this table of contents. In fact, it is the algorithm stated in the first sentence of this paragraph, "listing each library in order by name, and each function in alphabetical order by name within its library". Here is that algorithm expressed in pseudo code:
        
        ```(pseudo)
            create toc
                for each library sorted alphabetically
                    create toc-entry library name
                    for each function in library sorted alphabetically
                        create toc-entry function name
    
        {Tables of contents} serve different purposes. Some describe a curriculum, a designed reading order. Others are simply a means of navigation, a way to select one topic out of a collection of many. If your content is written in the {subject domain}, the chances are that it already contains the structures on which such a classification could be based, and again the {TOC} can be generated based on the {metadata} already in the content. 
        
        One advantage of this approach is that if a {TOC} is assembled based on {metadata} in the content, that means that when new content is added, it is automatically included in the TOC the next time output is generated. This simplifies the task of adding new content to a collection by avoiding the need to update multiple files or systems when a update occurs. This makes life easier for authors as they do not need to know how the TOC is constructed. They only have to create an individual piece of {conforming} content and submit it to the right location. This also constitutes yet another example of the {avoiding duplication}, since the basis for the content's inclusion at a particular point in the TOC is stored only in one place.  
        
    section: Lists
        A major feature of a {bottom-up information architecture} is the {list}. Like {tables of contents}, lists are a catalog of resources. But while a TOC is a list of resources defined by their container (contents = things in a container) a list may have any principle of organization or inclusion. 
        
        For instance, you might want to have a list of all the movies starring each actor in a collection of movie reviews. Such a list is not only a useful piece of information, they are also an important aid for navigating around a site. Maintaining such a list by hand would be laborious and error prone, especially with new movies being added to the collection all the time. 
        
        If you have your movie reviews in a structured format that lists the actors in the movie in a format accessible to algorithms, like this:  
        
        ```(sam)
            movie: Rio Bravo
                starring:: actor
                    John Wayne
                    Dean Martin    
                    Ricky Nelson    
                    Angie Dickinson
                    Walter Brennan
                    
        you can generate the filmographies for all your actors, like this:
        
        ```(pseudo)
            create-filmographies
                for each unique actor in movie/starring/actor 
                    create filmography named actor with link to actor
                    for each movie where starring/actor = actor
                        create entry named movie with link to movie
                        
        Tables of contents are a {top-down information architecture} device. You expect to find them at the top of the information set. List are a {bottom-up information architecture} device. You expect to find them as independent pages or as elements within a page. Thus if our collection includes the biographies of actors, and we want each biography to include the filmography, we can omit the filmography from the {subject domain} version of the biography and add it to the output in the {publishing algorithm}. 

        ```(pseudo)
            match actor-bio
                create html
                    create h1 "Biography: " + actor-name
                    continue
                    create h2 "Filmography"
                    for each movie-review where starring/actor = actor-name
                        create li 
                            create a with attribute href 
                             = address of movie-review
                                output movie-name
            
        Note the close relationship between rhetoric and navigation here. The generated filmography is both content and navigation, both part of the individual topic and part of the overall navigation scheme -- and example of how information architecture unites rhetoric and navigation.  

        It is also worth noting this kind of thing is a sophisticated example of the {reuse algorithm}. It takes a set of movies, each with a list of actors, and uses it to generate a list of movies for each actor, reusing existing information to create new content. This happens without any explicit reuse markup.  
    
    section: Personalized content 
    
        Another key feature of modern web architecture is personalized content, which means content that is generated in response either to what the site already knows about you (from your account information, or a transaction token such as a {cookie}(tool), or the  selections or entries that you make on the page). For example, when you log into Amazon, the first page you see is crafted for you based on everything Amazon knows about your browsing and purchasing history. As you make selections, such as adding an item to your shopping cart or wish list, that information is used to shape the next page you see. 
        
        If you browse a used car site like Autotrader.com, you can select those features of a car that you are interested in (red convertibles with manual transmission under $20000, for instance) and the next page will be built based on that input.
        
        The ability of a site to personalize pages depends on its ability to identify content that is {relevant}(algorithm "relevance"), based on everything it knows about the reader, and to assemble those pieces to form a page. For this to work, the content has to be easy to identify unambiguously, and it needs to be highly {composable}(algorithm "composability").  
        
        As we have seen, these properties are maximized when content is stored in the {subject domain}, both because the {subject domain} makes the relevant {metadata} available, and because working in the {subject domain} helps authors produce more consistent content that works better with these algorithms. 
        
        The consistency of the content is most important in any personalized content application. There is no possibility for an author or editor to inspect the output of a personalized content publication before the reader sees it, since it is assembled in real time based on the unique things we know about each reader. This requires total confidence that:

        * the content {conforms} to its {constraints} 
        * those constraints are completely and correctly expressed by its {markup} 
        * the algorithm correctly processes and delivers the content 

        All three of these requirements depend on the soundness and simplicity of the {markup} design. They require precise content structures with few alternatives, clear guidance for writers, and good {audit} capability. Without these properties, content and its markup will be inconsistent and reliable algorithms will be hard to write and test because of the wide variety of markup combination they may encounter. 

        Most personalized content applications model their content in relational database tables for these very reasons. However, with the correct markup design, almost certainly in the {subject domain}, there is no reason why you cannot use markup-based tools alone or in concert with database tools and solutions to achieve the same kind of thing. 
