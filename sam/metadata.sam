chapter:(#chapter.metadata) Metadata

    <<<(annotations.sam)

    We live in the age of metadata, so much so that the word metadata has almost come to replace the word data itself and has come to be applied to almost any form of data that describes a resource. For example, we hear a lot about law enforcement getting access to metadata related to phone calls, which simply means the data about which number called which number and for how long.  
    
    The standard definition of metadata is data that describes data, but that definition misses the central point. Metadata does not merely describe data, metadata creates data. Metadata turns an undifferentiated set of values into useful data by constraining the interpretation of those values. 

    In the {document domain}, the ingredients of a recipe are just list items. The content of those list items are just strings of characters.  
    
    ```(sam)
        section: Ingredients
            * 12 eggs
            * 2 qt water

    Adding {subject domain} markup allows us to specify to algorithms exactly what these strings mean.
    
    ```(sam)

        ingredients:: ingredient, quantity, unit
            eggs, 12, each
            water, 2, qt
    
    This subject domain markup is metadata, and it turns what were just list items into a set of ingredient data. It is not that the data existed and the metadata came along afterward to describe it. It is that the data exists as data only because the metadata is there to describe it. While a human reader can recognize that the values in the list are ingredients, based on their familiarity with the recipe format, an algorithm sees only strings of characters until we apply the metadata that lets it recognize them as ingredients.[*1]

    footnote:(*1)
        I am talking here about ordinary algorithms: simple rules written by humans to govern the processing of well defined data. As I noted in [#chapter.quality], advances in AI are making inroads on enabling robots to read the way humans do. An AI is an algorithm, and a sufficiently advanced AI algorithm might not need this level of explicit metadata to recognized list items are ingredients. Technically, though, such an AI would still be depending on metadata to interpret this data. It would just be using the same metadata that humans use, which we might fairly, if briefly, characterize as a combination of grammar and memory. Until such AIs are available to us, though, structured writing allows us to add more explicit metadata to content to make it accessible to simpler algorithms. 
    
    Structured writing is writing that obeys constraints and that records the constraints it obeys, so as to create an interface between partitions in your content system. In other words, structured writing is the application of metadata to content which turns content into data by constraining the interpretation of the content. If structured writing is writing that obeys constraints and records the constraints it obeys,  Metadata is the means by which those constraints are recorded. Metadata constrains the interpretation of values in content, making them accessible as data. 
    
    This is the basis for all partitioning of the complexity of content creation. The metadata we attach to content allows us to pass the content to different people or processes without letting any of the complexity drop. (This includes search engines and other downstream processes that we do not control but can inform.) We cannot partition complexity safely if we drop any of the complexity in the process. Metadata is how we ensure that all the complexity has been successfully transferred from one partition to another. 
    
    Another way of looking at this is: metadata preserves the information needed to make decisions about a piece of content. Preserving the fact that a piece of text records an ingredient lets us make decisions later about how to format ingredient listings or about which recipes to include in a collection. Explicitly recording which parts of that string are the quantity and unit of measure lets us make a decision later about which set of weights and measures should be used when presenting the recipe to a reader, allowing us to publish the content in other markets.  Partitioning the content system means moving complexity -- decisions -- from one partition to another. Metadata is how we record and transfer the information required to do that. If you want to transfer a decision from a writer to another person or process, for instance, you have to ask what information you need the writer to provide to that person or process in order for them to make and execute that decision. That information is the metadata that needs to be added to the content. 

    Saying the the subject domain metadata makes the text of the ingredients list more precise data is not the same as saying that a list structure is not metadata also. It is document domain metadata. It formally identifies a piece of text as a list item. It allows us to partition the formatting of lists from the writing of recipes, and all kinds of other content. This makes it easy to write algorithms that recognize lists which allows you to reliably format list items in whatever media you choose to publish in. The operations we can perform on list item data are obviously far less sophisticated than those we can perform on ingredient data, but list item data are still data and still created by metadata.  

    There is a very important point here: The same set of values, the same string of letters, words, and numbers, can be turned into different kinds of data by applying different kinds of metadata to them. This means that we can choose what kind of data we turn our content into by choosing what type of metadata we apply to it. Moving content from one structured writing domain to another means turning it into different kinds of data by applying different metadata to it. By turning it into different kinds of data, we make it accessible to different kinds of algorithms.     
        
    section: The recursive nature of metadata
    
        Metadata is a confusing concept because metadata is recursive. If metadata is the data that describes (and thereby creates) data, it is also data itself. And since data is created by metadata, this means that metadata is itself created by metadata. In other words, if the line `ingredients:: ingredient, quantity, unit` turns the ingredient lines into metadata in this markup: 
        
        ```(sam)
            ingredients:: ingredient, quantity, unit
                eggs, 12, each
                water, 2, qt
            
        Then what makes `ingredients:: ingredient, quantity, unit` a piece of metadata and not just another string of characters? Whatever it is, it is also metadata, and the content depends on that metadata as well, since it cannot exist without its metadata and that metadata cannot exist without the metadata that defines it. 
            
        In structured writing, we add structure to content to replace the things we have factored out. That structure is metadata to the data that is the text of the file. But if we store that file in any kind of repository, the information that identifies the file in that repository is metadata to the file as a whole. If the structure of the file is described by a {schema}, the schema is also metadata for the file. 
                
        But we're not done yet because the specification of the schema language is the metadata that tells you what the schema means.  And then of course, there is the specification of the markup to consider. The XML specification is part of the metadata tree for every XML document in existence. And we are still not be done, because the XML specification uses a formal grammar description language, called {BNF}(language). The BNF specification is metadata for the schema language description. 
        
        How do we break out of this infinite recursion of metadata? Data is information that has been formalized for interpretation by algorithms. Fortunately, human beings can understand natural language without that degree of formalization. Eventually, then, we reach a point where the last piece of metadata is not described by metadata but by human language. That human language document essentially bootstraps the whole metadata cascade that eventually yields pieces of data that can be unambiguously interpreted by algorithms. 
        
        So, every piece of data has a spreading tree of metadata supporting it, which, if traced to its roots, eventually leads to plain language documents that explain things in human terms. Thus the XML specification combines plain English definitions with BNF, if if we go to the BNF specification we will find the plain English definitions that describe BNF.
        
        
    section: Where should metadata live?
        
        One of the great questions about metadata is where it should live: with the data it describes or separate from it? We looked at this issue a little in [#chapter.content-management], but now that we have a better understanding of what metadata is, we can give a more complete answer to the question. 
        
        The issue of where metadata should live is closely related to the issue of how responsibilities are partitioned in your content system. Since metadata is how complexity is transferred safely from one partition to another, the responsibility for creating the metadata lies with the person or process in the originating partition, while the metadata requirements are dictated by the needs of the receiving partition. By adjusting how the system is partitioned, you can adjust how onerous the metadata requirements are on any one actor in the system. The location of the metadata, therefore, is essentially dictated by the partitioning. It is located in the place that achieves the desired partitioning of complexity for the particular content system. 

        Most early graphic file formats only stored the image. Most modern format also store extensive metadata about the image. The pictures you take with your digital camera include lots of information about the camera and the settings that were used to take the shot, all of which can help rendering algorithms and graphic editing applications the handle the raw image data better. Having that metadata embedded in the file ensure that the picture and its metadata stay together. Separating them would greatly complicate the system. Keeping the image metadata in the image file is better partitioning than keeping it separate. 

        Unfortunately, tools are often designed with other priorities in mind. For one thing, many tool developers think almost exclusively in relational database terms. The idea that you could store metadata anywhere other than relational tables is foreign to them. For another, system vendors have a vested interest in a partitioning of the process that requires every user to be interacting with their system all day long because this forces people to buy every contributor a licensed seat for their tool. Both these things encourage them to implement models in which the metadata is separate from the content, ensuring that you need access to the system to have access to the metadata.

        For example, should the history of a file be stored in the file or in the repository? Storing it in the file lessens the file's dependence on the repository and makes it more portable. But a repository vendor may prefer to sell you a system in which to uninstall their repository would be to lose all your file history. If file status information is only stored in a workflow system, for instance, it is very hard to move away from that system. It it is stored in the file, it is easy to move away, and also to edit when not connected to the system, which can save you on licenses. 

        In the case of the photo, the metadata is in the file because the camera is the best placed instrument to record it. This is the best partitioning of the complexity of the recording and transferring this information, both in terms of its convenience of creation and in terms of ease of access and management. The location of the metadata should be determined by the best partitioning of the content system, not the convenience of a tool vendor. 

        
        Writing your content in the subject domain means that more of your metadata is stored in the same file as the content, increasing its independence and portability. Also, as we have seen, the use of subject domain structures can lessen the need for management domain structures for algorithms like {single sourcing} and {content reuse}, which reduces the need for external management domain metadata. All of this contributes to improved functional lucidity, referential integrity, and change management.
        
        But this does not mean that all metadata related to an piece of content belongs in the content file. For example, when we import a graphic into a document, we often give it a caption or a title and we specify the size it should be displayed at. These are all metadata about the graphic, but it would not make sense to include this information in the graphic file itself. This information is not actually describing the graphic itself, it is describing its relationship to the current document. In a different document, the same graphic might be displayed at a different size with a different caption or title. This information is therefore included in the file that imports the graphic, not the graphic file itself. In other words, the metadata is stored on the right side of the relationship between the two content objects. This is simply good partitioning. (In [#chapter.wide] we  looked at another way of partitioning this metadata, again based on the nature of the relationship between the files, and on the way that the complexity of the content system is partitioned.)
        
        Storing the metadata on the right side of the relationship means that there are definitely types of metadata that belong on the repository or content management side of the relationship as well. If you store your content in a version control system (VCS) such as GIT (something that is increasingly popular in the "treat docs like code" movement), the VCS will record the difference between each version of the file you submit as well as who did each commit of the file. This will allow the VCS to do valuable management things like tell you exactly who changed an individual line of a file and on what date they changed it. Storing such metadata in the file itself would make it impossible complex to author. Again, the metadata is stored on the right side of the relationship and the partitioning of complexity is correct. 
                    
    section: Ontology
        Finally it is worth saying a word about ontology. Ontology (in the information processing sense) is an attempt to create a formal mapping of the relationships between entities in the real world such that algorithms can draw inferences and reach conclusions about them.  
        
        In many way, therefore, an ontology is an attempt to do for algorithms what content does for humans. After all, one of the main reasons that we read is so that we can understand the world better, understand what various objects and institutions are and how they relate to each other, statically and in action, so that we can decide what to do. 
        
        In some sense, therefore, ontology is the ultimate in {subject domain} markup. Indeed, one should also be able to generate human-readable content from an ontology, given a sufficiently sophisticated algorithm and a sufficiently sophisticated ontology. 
        
        All of this is very much outside our scope in this book. {Subject domain} markup is an attempt to capture certain aspects of the subject matter of a work. But it is not an attempt to model the argument of a work. Consider the passage:
        
        ```(sam)
            In {Rio Bravo}(movie), {the Duke}(actor "John Wayne") 
            plays an ex-Union colonel.
            
        Here the subject domain markup formalizes the fact that Rio Bravo is a movie and that "the Duke" is a reference to the actor John Wayne. It does not model the relationship between the two. An ontology would want to model the "starred in" relationship between John Wayne and Rio Bravo, whereas  {subject domain} structured writing is normally content to leave this to the text. 
        
        Similarly, this {subject domain} markup does not bother to denote that Union is a reference to both a country and its armed forces, and that colonel is a rank in those armed forces. It does not denote these things because this particular markup language is concerned with movies and these facts are entirely incidental to the movie business. Actors, directors, and movies are significant subjects in the movie review domain. The names of nations and their armies that figure in the plot of individual movies are incidental in that domain. A full ontological treatment of the passage above, however, would need to model those relationships. 
        
        Structured writing does make certain aspects of content clear to algorithms, but not with the intention of making it possible for the algorithms to make real-world inferences and decisions based on the information in that content. It only does what is necessary to partition and redirect content complexity in a content system in which human authors to use algorithms as tools to improve the quality of the content they prepare for human readers. 
