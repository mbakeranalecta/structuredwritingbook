!smart-quotes: on
chapter:(#chapter.taxonomy) Terminology
    <<<(annotations.sam)
    subjects::type, term
        concept, taxonomy
        concept, terminology
        concept, controlled vocabulary

    Whether you store metadata internally in the content or externally in a content management system (CMS), it is important to keep terminology consistent. Similarly, it is important to name subjects in the content consistently to avoid confusing readers. And if you provide a top-down navigation scheme for your content, you need to choose the right terms to name the subjects so that readers can find them.[*fn.xlate] 

    footnote:(*fn.xlate)
        Control of terminology is important for translation as well, but that is outside the scope of this book.

    For all of these reasons, large-scale content projects need to control terminology. Managing terminology is complex, and taking a simplistic approach can result in dropped complexity and compromised rhetoric in the form of incomprehensible language, incorrect classification, or poor connections between units of content. 
    
    The biggest danger is thinking of terminology as a simple data-management problem. Separating words from their role in sentences and paragraphs makes them easier to fit into the traditional rows and columns of data management, which makes the problem look simpler than it is. If you approach terminology management in this way, it might seem straightforward to get a bunch of people in a room, spin up a list of words and their definitions, and declare the result as your corporate taxonomy, but this is a false partitioning of the problem. 
    
    The principal difficulties in establishing terminology include the following:
    
    * Human beings have a fairly small active vocabulary, and we reuse words all the time. In safety critical functions like air traffic control or the operating room, we train everyone to use a special unambiguous vocabulary that is generally undecipherable to the layperson.[*fn.or] But usually, the words you want to control are used in multiple ways that are not easy to disambiguate formally. 
    
    * People in different fields (even within the same organization) often use different terms for the same concept. What the chef calls _pork_, the farmer calls _pig_. What the English call _boot_, North Americans call _trunk_. Forcing everyone to use the same term means forcing them to say things that don't make sense in their own field. 
    
    * People in different fields (even within the same organization) often use the same words to mean different things. What the conference organizer calls a _function_ is not what the programmer calls a function. What a programmer calls a function is (in more subtle ways) not what a mathematician calls a function.
    
    * People in one field may have ten terms that make fine-grained distinctions among things that people in another field lump together under a single term. For instance, programmers make a distinction between subroutines, functions, methods, and procedures. I know of one documentation project that mandated that all of these should be called routines. This worked most of the time, but became a problem when function pointers were introduced into the product, because you can't use the modifier _pointer_ with any of the other terms. Enforcing a single term obscured an important distinction.  

    footnote:(*fn.or)
        In fact, we not only train them, we also test and certify their knowledge before we let them in the room. Getting people to use a specialized vocabulary consistently and in a precise way is so difficult that it becomes a major factor in the development and licensing of professionals in safety critical functions. Merely issuing a glossary or taxonomy to an organization is not going to do the trick.

    In short, very little of our terminology is truly universal. The meaning of words changes depending on the context and the audience. This is at the core of how language works and why language is different from other forms of data. Content tells stories, and what words mean depends on the context in which they are used in the story. Stories are not as precise as formal data, but the only way to define formal data is with stories. This is why the spreading tree of metadata that supports and explains any point of data always ends with narrative. Structured writing attempts to apply some of the orderliness and manageability of data to stories in order to improve their quality and consistency, allowing us to communicate more effectively. 

    Terminology control is key to making your structures and metadata work. However, at the same time you must use care and sensitivity and understand the limits within which you can control the terms you use to tell stories. Good taxonomies define their terminology within the confines of a specific domain, but in all but the most strictly controlled domains (such as the operating theater or the control tower), individual words have shades of meaning that can be fully disambiguated only in the context of a particular story.
    
    In [#chapter.separating], we saw how you can use context to determine the meaning of block names. Terms don't have to be universally unique as long as you can identify them unambiguously in context. Terms that cannot easily be controlled universally can often be controlled in context. Appropriate partitioning makes the terminology problem much more tractable. Structured writing helps you partition the terminology problem by providing the context in which terms are understood.

    In [#chapter.linking], we saw that subject annotations can be made more precise by identifying the type of subject being named. Here again you are adding context to terminology to control it better in its local domain. One of the virtues of the subject domain is that every subject-domain content type and indeed every subject-domain block type provides context for controlling the interpretation of the terminology within it. This is another instance of using structured writing to constrain the interpretation of content.
        
    section: Top-down terminology control
        
        There are two ways to partition the terminology control problem: top down or bottom up. The principle tools of top-down management are controlled vocabularies and taxonomies. A controlled vocabulary is essentially a list of terms and their proper usage within a specific domain. 
        
        A taxonomy is a more elaborate scheme for controlling and categorizing the names of things. Taxonomies are frequently hierarchical in nature, defining not only the terms for individual things but the names for the classes of things. Thus, a taxonomy does not just list sparrows and blue jays and robins, it also classifies them as birds, birds as animals, and animals as living things. A good taxonomy should be specific to the domain for which it is intended. Blue Jays and Cardinals occupy a very different place in a baseball taxonomy than in a ornithological taxonomy.[*fn.birds] As a classification scheme, you can use a taxonomy not only as the basis for controlling vocabulary, but also as a basis for top-down navigation of a content set. 

        footnote:(*fn.birds)
            This reference to Blue Jays and Cardinals is culturally dependent. Readers outside North America may not recognize these as the names of baseball teams. This is a concern for terminology management and could call for differences in rhetoric in different markets, such as a footnote to explain the reference or a totally different example that better explains the concept to another culture.
        
        Alternatively, you can control terminology from the bottom up. To do this, you use {subject-domain} {annotations} in your content to highlight key terms and place the usage in the appropriate domain.
        
        ```(sam)
            In {Rio Bravo}(movie), {the Duke}(actor "John Wayne") plays 
            an ex-Union colonel.

        In the passage above, the annotations call out the fact that "Rio Bravo" is the name of a movie and "the Duke" is the name of an actor called John Wayne.
        
        This is taxonomic information. It places Rio Bravo in the class `movie` and John Wayne in the class `actor`, with the added information that the Duke is, in this context, an alternate term for the actor John Wayne. Placing these terms in these classes makes it clear that Rio Bravo, in this context, is not the Mexican name for what Americans call the Rio Grande or any of the several towns named Rio Bravo and that the Duke refers to John Wayne and not to the Duke of Wellington (who was often called by that nickname) or any of the other possible meanings of Duke. In other words, the taxonomy is embedded in the content. The {subject domain} internalizes taxonomic metadata. 
        
        To appreciate why this might be useful, let's look at some of the challenges of maintaining and enforcing vocabulary constraints. 
        
        As mentioned above, constraining vocabulary is hard because the same term can mean different things in different contexts, and different terms can mean the same thing in different contexts. If you attempt to build a taxonomy from the top down it can be difficult to anticipate the various meanings a term may have in different contexts. Even if you study existing content -- a tedious and time consuming search -- there is no guarantee you will exhaust all the possibilities.
        
        Secondly, after you define your top-down taxonomy, how do you enforce it? You can require writers to use terms from the taxonomy, but how is that going to work? Do you expect them to carry the entire taxonomy around in their heads? Do you expect them to recognize when they attempt to use a word that has a synonym in the taxonomy but isn't in the taxonomy itself? Such requirements create mental overhead for writers, and, as I noted in [#chapter.writing], dividing a writer's attention has a negative impact on content quality. A top-down taxonomy dumps a complex task, which depends on a huge amount of data, onto writers and requires them to pay attention to it continuously in every word they write. This is the antithesis of good partitioning of complexity.
        
        There are mechanical solutions that attempt to catch terminology problems, but the fact that words can mean so many things in different contexts means no such process can get it right all the time. 

    section: Bottom-up terminology control
    
        An alternative to defining and enforcing a taxonomy from the top down it to let it emerge, in a disciplined way, from the content itself. The key to this, particularly in the subject domain, is for writers to annotate the things that are significant as they are writing. If the terminology you are trying to enforce is not terminology that is significant to your content, you are wasting your time. 
        
        If writers annotate the significant subjects in their content as they write, they will be annotating the terms you want to control. So, when they mention the name of a bird like blue jay or robin, they should annotate it as `{blue jay}(bird)` or `{robin}(bird)`. By specifying the type of the subject, they are partitioning the vocabulary in context.  
        
        Of course, this does not ensure that writers use the right terms for birds. It only highlights the terms they actually use. To achieve consistency, you need to {audit} the list of birds mentioned in your content. To get the current list of bird names from the content, you have an algorithm scan your content for terms annotated as `bird` and compile them into a sorted list. This is one of those query-oriented algorithms that I mention at the end of [#chapter.processing] and an application of the {content-generation algorithm} discussed in [#chapter.generate]. You can then quickly see if any incorrect or unexpected terms are being used, and you can either edit them or call them to the writer's attention. This partitions the vocabulary control problem in a way that makes it easier for both the writer and the person managing terminology -- who I call a {terminologist}+(italic) -- to do their jobs. 

        Notice that you are not introducing a new role here. Even if you demand that writers follow the taxonomy up front, they will make mistakes, and you will need to audit anyway, unless you are willing to live with the mistakes that result from that dropped complexity. This approach simply makes the audit easier to perform by highlighting the use of terms, and assigning them to the correct domains, in the text.        

    section: Creating and maintaining a taxonomy
    
        This approach not only works to audit conformance to an existing taxonomy, it can also be used to create and maintain a taxonomy. If a writer mentions a new bird that you didn't include in your taxonomy, it will show up in the list for the next audit. You can then decide if that bird should be added to the taxonomy or not. 
        
        Adding terms to the taxonomy does not necessarily imply that you maintain a top-down taxonomy that is separate from the content itself. You can regard the current annotated content set itself as the taxonomy. After all, it contains all the approved terms and their types. Any list of terms you generate from the content are just reports on the taxonomy, not the taxonomy itself. By storing a report from the previous {audit}, you can compare to see if any terms have been added to the taxonomy since the last audit. 

        This approach may not always give you sufficiently firm control over your taxonomy, so you may, instead, use annotations in your content as an indication that writers are using new words, and you can then add them (or not) to the official taxonomy list. 

        If you maintain an official taxonomy separate from the content, it is trivial to have an algorithm compare the audit list to the official taxonomy and alert you every time a new bird is mentioned. Effectively, now, your taxonomy is bubbling up from your content. Your writers do not need to worry about whether the terms they use are in the taxonomy or not, as long as they mark up what type of thing they are naming. You can run the audit-and-compare algorithm regularly (nightly perhaps) and have it alert your {terminologist} every time a new term is added to the content. The terminologist can evaluate whether the term is being used correctly and whether or not it should be added to the taxonomy. This way, the terminology {audit} is almost entirely automated, with action required from the terminologist only when a writer uses an unfamiliar term. 

        Writers may forget to annotate some birds or may annotate them incorrectly (as something other than a bird). But you can easily catch most of these mistakes as well. Incorrect annotations tend to show up as anomalous entries in other annotation categories. If "sparrow" shows up in the `bards` category next to Shakespeare, the {terminologist} will get an alert that a new bard has been mentioned and can easily see and fix the mistake.
        
        When there are genuine name conflicts between two different domains, you can list the conflicting names, use an algorithm to compile a list of all tagged instances of those names, and review them for incorrect tagging. To catch omitted tags, you can have an algorithm scan the entire content set for unannotated instances of annotated terms. If you get a lot of false hits (the same words used in a different context), you can annotate them to be ignored:

        ```(sam)
            It reminded me of {Robin}(ignore) Hood.

        section: Centralized versus distributed allocation of complexity
            The point of partitioning and redistributing the complexity of a problem is to direct the complexity to those best placed to handle it. This sometimes means directing complexity to a central person or process with specialized knowledge, such as knowledge of the organization's formatting standards. But just as often it means distributing the complexity outward or down to people in the field who have the contextual knowledge needed to make the correct decision.

            Taxonomy is a third case that combines distribution of complexity and centralization. Only the writers in the field can tell you what ideas need to be expressed, and only a central process can coordinate and disseminate information about what terms have been added to the taxonomy. Any process that does not allow communication in both directions, and does not allow writers to make good decisions in context, will damage rhetoric and make content less accessible to readers. Equally important is how complex you allow each person's task to become and how many things you ask them to do at the same time. Even if writer and {terminologist} are the same person, the approach to terminology control outlined above separates the tasks in time, so that writers do not have to keep the taxonomy in their head as they write. In fact, it means that no one has to keep the taxonomy in their head at all.  
        
        section: Stop lists
            Another useful {conformance} tool that can come out of the bottom-up approach is a {stop list}. A stop list is a list of terms that should not be used. You can have an algorithm scan content against a stop list to identify inappropriate vocabulary. Stop lists can only really be created bottom up. You can't anticipate or ban every term anyone might ever come up with. You should only ban terms that are both problematic and occur frequently. The chance of false hits -- of banning terms that are perfectly legitimate in other contexts -- rises with every word you add to the stop list. With a bottom up approach to terminology control, you get an accurate measure of which terms are being misused and the frequency and nature of the misuse. This is an excellent basis for compiling a useful stop list.  
        
            Also, because subject annotation can specify the type of a term (that is, distinguish between `{Blue Jays}(baseball-team)` and `{Blue Jays}(bird)` you can make a type-specific stop list, banning works used in one sense but not another. This can greatly reduce false hits, which is important because people won't use conformance tools if they produce too many false hits, as you can see from how infrequently writers use the grammar checkers in word processors. 

            The bottom-up approach does not make all vocabulary constraint problems go away, but it does have a number of advantages. 
        
            * It turns an up-front taxonomy development effort into an ongoing, permanent part of the content development process. This not only reduces the up-front spike in effort, it also helps ensure that your taxonomy is based on real experience writing real content and that it is continually maintained as subjects and business objectives change. Indeed, if you already annotate your content to support any of the other structured writing algorithms, you essentially get taxonomy development, maintenance, and control almost for free. Of course, someone does have to review the reports, make the edits, and add to the canonical taxonomy.
        
            * It improves {functional lucidity} by not forcing writers to refer to the taxonomy while writing. If you are already annotating subjects for other reasons, you are imposing no additional burden on writers at all. 
        
            * By improving the consistency of the annotations, it makes the algorithms that rely on annotations more reliable. This is one of the greatest virtues of the subject domain. Subject-domain markup can serve multiple algorithms, meaning you get the benefits of multiple algorithms with less cost. 
        

