chapter:(#chapter.quality) Quality in Structured Writing

    <<<(annotations.sam)

    index:: type, term
        concept, quality

    When I talk to programmers about what I do, they sometimes ask me why structured content is important any more. Machines are getting so good at reading human language, they argue, that semantic markup to assist the machine is increasingly becoming pointless. 
    
    section: Robots that read
    
        Indeed, machines are getting better and better at understanding human language. An approach called Deep Learning is increasingly becoming a key technology for companies like Facebook, Google, and Baidu for both {language comprehension}[http://www.technologyreview.com/featuredstory/540001/teaching-machines-to-understand-us/] and {speech recognition}[http://www.technologyreview.com/news/544651/baidus-deep-learning-system-rivals-people-at-speech-recognition/]. 
        
        The semantic web initiative has long sought to create a Web that is not just people talking to people but also machines talking to machines. This has traditionally involved an essentially separate communication channel -- semantic markup embedded in texts but not presented to the human reader. It has also involved the creation of specialized semantic data stores with query languages to match, to teach computers to understand relationships that humans would express in ordinary language. 
        
        But this two-channel approach -- one text for the human, another for the machine -- only makes sense if we assume that the machine cannot read human language. If machine and human can both read the same text then we shouldn't need two channels. The human Web becomes the semantic Web.
        
        After all, the human text always was semantic. Semantics is simply the study of meaning. All meaningful texts have semantics. It is just that it has been difficult to build algorithms that could read and understand like humans do. Semantic technologies are about dumbing the semantics down for the machine because the machine is not bright enough to read the regular semantics. 
        
    section: Dumbing it down for the robots
        
        This dumbing down necessarily involves omitting a great deal of the semantics of the text. Fully expressing all the meaning and implications of even the simplest text in {RDF triples}(concept), for instance, would be daunting. This has always created a problem for semantic technologies: which semantics do you select to dumb down to the machine's level, and for what purpose? This is why there is no universal approach to structured writing that works for all purposes and all subject matter. You can only represent a fraction of the human semantics to the machine, and which you choose depends on what specific functions you want the machine to perform. 
        
        But if the machine could read the text as well as you can, then these limitation vanish. Deep learning is moving us in that direction.
        
        Why then should we bother with structured writing? Quite simply because while machines may be rapidly learning to read human text, that text is still written by humans, and most humans are not good writers. 
        
    section: Making humans better writers
        
        By that I don't just mean that they use poor grammar or spelling or that they create run-on sentences or use the passive voice too much, though all those things may be true, and annoying. I mean something more fundamental than that: they don't say the right things in the right way for the right audience. They leave out stuff that needs to be said, or they weigh it down with stuff that does not need to be said, or they say it in a way that is hard to understand. 
        
        We all suffer from a malady called {the Curse of Knowledge}(concept)[https://en.wikipedia.org/wiki/Curse_of_knowledge] which makes it difficult for us to understand what it is like not to understand something we know. We take shortcuts, we make assumptions, we say things in obscure ways, and we just plain leave stuff out. 
        
        This is not a result of mere carelessness. {The efficiency of human communication rests on our ability to assume that the person we are communicating with shares a huge collection of experiences, ideas, and vocabulary in common with us.}[http://everypageispageone.com/2015/08/04/the-economy-of-language-or-why-we-argue-about-words/] Laboriously stating the obvious is as much a writing fault as omitting the necessary. Yet what is obvious to one reader may be obscure to another. The curse of knowledge is that as soon as something becomes obvious to us, we can no longer imagine it being obscure to someone else. 
        
        Thus much of human to human communication fails. The recipient of the communication simply does not understand it or does not receive the information they need because the writer left it out. Machines may learn to be better readers than we are, but even machines are not going to learn to read information that just isn't there. 
        
    section: We write better for robots than we do for humans
        
        Actually, one of the advantages of the relative stupidity of robots is that is forces us to be very careful in how we create and structure data for machines to act on. The computer science community coined the phrase "garbage in, garbage out" very early, because the machines were, and to a large extent still are, too stupid to know when the information they were taking in was garbage, and did not have the capacity, like human beings, to seek clarification or consult other sources. They just spit out garbage. 
        
        This meant that we had to put a huge emphasis on improving the quality and precision of the data going in. We diligently worked out its structures and put elaborate audit mechanisms in place to make sure that it was complete and correct before we fed it to the machine. 
        
        We have never been as diligent in improving the quality of the content that we have fed to human beings. Faced with poor content, human beings do not halt and catch fire; they either lose interest or do more research. Given our adaptability as researchers and our tenacity in pursuing things that really matter to us, we often manage to muddle through bad content, though at considerable economic cost. And the distance that often separates writers from readers means that the writers often have no notion of what the poor reader is going through. If readers did halt and catch fire, we might put more effort and attention into content quality.
        
        Even today, when a huge emphasis is being placed on enterprise content management and the ability to make the store of corporate knowledge available to all employees, most of the emphasis is on making content easier to find, not on making it more worth finding. (This despite the fact that the best thing you can do to make content easy to find it to make it more worth finding.) People trying to build the semantic web spend a lot of time trying to make the data they prepare for machines correct, precise, and complete. We don't do nearly as much for humans. Until we do, deep learning alone may not be enough to make the human web the semantic web.
        
        Part of the problem has always been that improving content quality runs up against the {curse of knowledge}(concept). Both the authors who create the content and most of the subject matter experts who review it suffer from the curse, meaning that there are few effective ways to audit written content. Style guides and templates can help remind authors of what is needed, but their requirements are difficult to remember and compliance is hard to audit, meaning there is little feedback for an author who strays. 
        
        The curse of knowledge and the distance separating writers from readers are a major source of complexity in the content creation process. Structured writing provides a way to guide and audit content for quality.   My reply to the people who ask me whether structured writing is relevant, therefore, is "garbage in, garbage out". Structured writing enables us to write in the subject domain (wholly or partially) and this allows us to guide and audit in ways not otherwise possible. It also allows us to factor out many constraints, simplifying the author's task, and therefore allowing them to give more of their attention to the writing task. These things make content better, whether that content is going to be read by people or by robots. 

    section: Structure, art, and science        
    
        To many writers, the idea that imposing constraints can improve quality is controversial. Many see quality writing as a uniquely human and individual act, an art, not a science, something immune to the encroachment of algorithms and robots. But I would suggest that the use of structures and algorithms as tools does not diminish the human and artistic aspects of writing. Rather, it supplements and enhances them. 
    
        And I would suggest that this is a pattern we see in all the arts. Music has always depended on the making and the perfecting of instruments as tools of the musician. Similarly the mathematics of musical theory gave us {well tempered tuning}(concept), on which modern Western music is based.
        
        {Computer programming is widely regarded as an art}[http://ruben.verborgh.org/blog/2013/02/21/programming-is-an-art/] among its practitioners, but the use of sound structures is recognized as an inseparable part of that art. Art lies not in the rejection of structure but in its mature and creative use. As noted computer scientist Donald Knuth observes in his essay, {Computer Programming as an Art}(citetitle), most fields are not either an art or a science, but a mixture of both.
        
        """[http://dl.acm.org/citation.cfm?id=361612]
            Apparently most authors who examine such a question come to this same conclusion, that their subject is both a science and an art, whatever their subject is. I found a book about elementary photography, written in 1893, which stated that "the development of the photographic image is both an art and a science". In fact, when I first picked up a dictionary in order to study the words "art" and "science," I happened to glance at the editor's preface, which began by saying, "The making of a dictionary is both a science and an art." 
        
        As writers we can use structures, patterns, and algorithms as aids to art, just like every other profession.
        
        Of course, few writers would claim that there is no structure involved in writing. We have long recognized the importance of grammatical structure and rhetorical structure in enhancing communication. The question is, can the type of structures the structured writing proposes improve our writing, and if so, in what areas? Traditional poetry is highly structured, but it is doubtful that using an {XML schema}(tool) would help you write a better sonnet. On the other hand, it is clear that following the accepted rhetorical pattern of a recipe would help you write a better cookbook, and using structured writing to create your recipes can help you both improve the consistency of your recipes and to produce them more efficiently and exploit them as assets in new ways.
        
        The question then becomes, how much of our work is like recipes and would benefit from structured writing, and how much is like sonnets and would not. The answer, I believe, is that a great deal of business and technical communication, at least, can benefit greatly. If you look at much of that communication and see no obvious structure, I would suggest that this is not evidence that structure is inappropriate, but that appropriate structure has not been developed and applied to the content.
        
    section: Contra-structured content
        
        We must also acknowledge that many writers have had a bad experience with structured writing. In many of these cases, the structured writing system was not chosen or designed by the writers to enhance their art; it was imposed externally for some other purpose, such to to facilitate the operation of a content management system or make it easier to reuse content. In other words, they were designed to shift complexity away from some other function without sufficient thought about where that complexity would go, and it ended up being dumped on the writers. In some cases, these systems actively interfere with the author's art and directly hinder the production of quality content.
                
        Writers who have had bad experiences with structured content have usually been faced with structures that were not designed for the writer's purpose. Such content is not merely unstructured for these author's purposes, it is actually contra-structured. It has an enforced structured that actively gets in the way of the author doing their best work. 
        
        I talk to authors all the time who show me page designs and layouts that make no sense, lamenting that the system does not give them any other choices. Content structure is not generic, and you cannot expect to simply install the flavor of the month CMS or structured writing system and get a good outcome. 
        
        Properly applied, however, as a means to guide and enhance the work of authors, structured writing can substantially improve content quality. In upcoming chapters, we will look at the algorithms of structured content, many of which relate directly to the enhancement of content quality.
        
    section: Until the robots take over
    
        Of course, this all supposes that the machines are not becoming better writers than us as well. Companies like Narrative Science are working on that, but I don't know if they are as far along that path as the deep learning folks are in teaching computers to read. 
        
        Do robots suffer from the {curse of knowledge}? Maybe not. But current writing robots certainly work with highly structured data, so structured writing is still key to quality content even when the robots do come for our keyboards.
        
        Actually, according to James Bessen's recent article in The Atlantic, {The Automation Paradox}[http://www.theatlantic.com/business/archive/2016/01/automation-paradox/424437/], automation does not decimate white collar jobs the way we have been told to fear. By reducing costs, it increases demand, resulting in net growth of jobs, at least for people who learn to use the new technology effectively. 
        
        That said, all the semantic technology and content management in the world is not going to make the difference it should until we improve the quality of content on a consistent basis. Structured writing, particularly structured writing in the subject domain, is one of our best tools for doing that. 

        When we use structured writing to partition the complexity of the content system, we are partitioning much of that complexity to algorithms. This means that functions that used to be performed by people will now be performed by algorithms. This means that the people who are responsible for these functions will no longer be doing them by hand but will instead by responsible for defining, creating, and maintaining the algorithms that do them. This can include writers, who may create structures and algorithms to guide the rhetorical structure of content or to validate and audit content. If they don't create these algorithms themselves, they will at least need to understand how to commission others to do it for them. 

        For this reason, the study of structured writing is first and foremost the study of algorithms. The chapters in this section will explore each of the main structured content algorithms, looking at both the function the algorithm performs and the structures that define the interfaces that supply information to those algorithms. However, these are not chapters on programming. Defining an algorithm for a process and writing software to implement that algorithm are two separate tasks. They may be performed by the same person or by different people. But the aim of this section is to introduce you to the design and capability of structured writing algorithms, not to the coding of software. 

        The chapters in this section cover a wide range of subjects, from publishing to reuse, from linking to collaboration, and from authoring to auditing. Some of these go well beyond what we think of as traditional publishing or content management functions. They also consider how each algorithm is performed in each of the structured writing domains. Some algorithms can be implemented in different domains. Some can only be effectively addressed in some of the domains, and the difference in both approach and reliability between implementations in different domains can be substantial. 

        As you go through these algorithms, however, be careful not to get too attached to any one domain or any one algorithm. As I noted at the beginning, quality in a modern content system is produced by partitioning the complexity of the whole systems so that every part of that complexity is handled by a person or process with the skills, time, and resources to handle it completely. Implementing any one algorithm in isolation can result in complexity being distributed out to other parts of the content system that are not well equipped to handle it. The aim is not to optimize any one function, but to ensure that complexity is being handled effectively across the whole content system. That will require a combination of algorithms designed to partition the content system appropriately to handle the unique set of factors that contribute complexity to your individual content system. 

        
    section: Algorithms overview

        The rest of this part of the book consists of an examination of the principle structured content algorithms. We use algorithms you help us partition the content system. Partitioning the system with algorithms serves two basic goals, improving quality and reducing costs. Each of the algorithms we will look at serves one or both of these goals. Sometimes, as we will see, these two goals can be at odds with each other. 

        We will also see that each of algorithms can be approached differently in each of the structured writing domains. The choice of domains can radically shift the cost and quality effects of an algorithm, as well as the ways in which the content system is partitioned. 

        When going through the algorithms, it is important to remember that the overall goal is to partition your whole content system so that every part of the complexity of your content system is handled by a person or process with the skills, time, and resources to handle it. Your focus should not be on implementing any single algorithm, therefore, but on using the appropriate algorithms, and the appropriate structured writing domains, to optimize your whole system. 

        section: Authoring

            We will being the examination of algorithms with authoring. While authoring is a fundamentally human task (at leas until the machines come for our keyboards), in a structured writing system, the input for your algorithms is the structured content that your writers produce. The success of your entire structured writing system, and the effectiveness of the partitioning you have implemented, rests on the quality of the content and structures that you writer's create. The worst mistake you can make in structured writing is to design algorithms without thinking about how the input content will get written, and the effect the writing environment will have on content quality and consistency. All structured writing algorithms start with authoring. 

        section: The basics      

            The next two chapters will review the basics of structured writing: how we partition the various elements of our content and how we put them back together again. The classic piece of content partitioning that everyone has heard of is {separating content form formatting}, so we will look at how this is done. In doing so we will examine all the basic techniques that will be used to enable all the other algorithm. 

            Then we will look at how to describe the algorithms for uniting content and formatting for publishing. Here again we will learn a few basic principles that will apply to all the other algorithms we will examine.   

        section: Single sourcing and reuse

            The classic applications of structure writing and content reuse. As we will see, there is far more to structured writing than just these things, but they remain an important part of the structured writing picture. 

            We will look at {single sourcing}, and see that, depending on how different our target outputs are, we may require more or less separation and may need to use different domains to get the partitioning we need, particularly when we need to practice differential single sourcing -- creating different forms of content for different audiences and different media. 

            We will look at the several different techniques that can be used to {reuse} content, and the pluses and minuses of each. Here again we will see that the use of different domains can make a big difference in both quality and efficiency. 

            We will then look at the related problem of {composition}: creating content that can be assembled like building blocks, and the quality pitfalls that lies in wait in this area.

            Then we will look at the problem of {avoiding duplication} and see that the central problem is to define when two pieces of content are duplicates, and when they are useful variations. Again we will see that implementing a duplication detection and avoidance system can work very different in the different structured writing domains.   

        section: Linking and the connections between subjects

            Next we will look at {linking}, and I will show that linking is really a larger problem than managing links. Linking is actually about managing the relationship between content and its subject matter. In a {differential single-sourcing} situation you may want to handle this differently in different media, using links in some media and other devices in others. This requires a step back from thinking about links to thinking about the relationships between subjects and the content that describes them. In this case, the choice between the {document domain} and the {subject domain} becomes absolutely crucial to both quality and efficiency. 

        section: Quality control

            One of the less appreciated aspects of structured writing is the huge role it can play in content quality control. We will look at two quality control algorithms that can have a huge impact on both quality and efficiency. 

            The first of these is the {conformance} algorithm, which is concerned with making sure that your writers, and all the other roles that contribute to your content system, consistently produce work that meets your quality standards. We will look at three fundamental components of conformance: factoring out constraints, enforcing constraints, and enabling and encouraging voluntary conformance. 

            The second quality control algorithm is {auditing}: the ability to ascertain at any given moment the state of your content set, what your have, what you need, and how conformant it is. 

            Again we will see that the choice of the domain in which you create your content can have a huge impact on the degree of conformance you can achieve and the cost, reliability, and extent of the auditing you can do.   

        section: Finding content

            The ability to find content is crucial. It is essential to writers, to content managers, to readers, and to algorithms. The key to finding things is the {relevance algorithm}. Searchers seeks content that is relevant to their concerns. The relevance algorithm is about first making sure that content expresses its relevance, so it can be found, and second that it actually is relevant audience and the subject matter it claims to be. 

        section: Generating content

            Not all content has to be written from scratch. Much commercial content is essentially the narration of company or product data and algorithms can make the process of narrating that data much faster and more reliable. As a bonus, generated content can also be an enormously useful resource for auditing the rest of your content set. 

            There are three algorithms used in generating content. The first is the {extract algorithm}, which pulls content out of existing data sources and puts it into a format that can be published as content. 

            The second is the {merge algorithm}. Often the content our readers need is a combination of generated content and content written by writers. The merge algorithm enables us to take extracted and written content and combine them to create useful outputs for readers. 

            The third is the {modeling algorithm}. In some cases, extracting content to describe some highly regular aspect of a system would make perfect sense, but there is no existing data set to draw the information from. In these cases, we can use structured writing techniques to create data that model the product or process we are documenting so that we can use extract and merge techniques to generate content. The model can also be a major source of data for {auditing} other parts of your content.    

        section: Information architecture

            {Information architecture} is the overall arrangement of a content set so that readers can find information. It covers everything from the purpose and scope of individual documents to linking, search, and navigational aids. Maintaining a consistent and effective information architecture, especially on a large and constantly changing site, is dauntingly complex. Structured writing techniques can not only help you define and manage your information architecture, and audit its effectiveness, they can be used to generate and maintain architectural features that would not be possible by individual human effort. Again we will see that the choice of domain is crucial to both quality and efficiency in information architecture. 

        section: Managing content and process

            Content has to be manged, and the management of content introduces lot of complexity into the content process. As we will see in these chapters, the effective management of content cannot be separated from its structure. In fact, its structure is key to its manageability. 

            One of the largest sources of complexity in the content system is dealing with changes in subject matter and business requirements, a problem that has become much more acute in the age of the Web where everyone expects all content to be constantly up to date. The structure of content deeply effects your ability to find content that needs to change, to change it quickly and effectively, and to deal with the ripple effects of change. 

            In a large content organization, were the activity of many contributors have to be coordinated, the management of content assets themselves becomes a major source of complexity. {Content management} system are themselves highly structured, and the structure of the content management system and the structures of the content meet and may overlap. Matching your content management strategy to the structure of your content is key to distributing content management complexity effectively.

            {Collaboration} has become an ever more important part of the content system as the Web forces us to deliver information in real time and to continually integrate the work of many different contributors. Without effective partitioning, the overhead of collaboration an overwhelm a system making it impossible to keep to schedule and maintain quality. Specific approaches to structured writing, particularly in the {subject domain} can greatly reduce collaboration overhead and allow diverse contributions from diverse contributors to be integrated smoothly into the content collection. 
            
            The immediacy of the Web and the speed of modern commerce make {timeliness} and indispensable aspect of modern content. Yet handling the complexities of the content process can significantly slow the pace at which content goes from requirement to writing to publishing. All of the structured writing algorithms can contribute to enhanced timeliness, but most important of all is using them together in a way that ensures the no complexity is neglected in the process of getting content rapidly to market. 

            Finally, {repeatability} is the core goal of all management processes. Doing the right thing once is a work of craft. Ensuring that the right thing is done time after time is a work of management. But repeatability in content is about more than ensuring a efficient process. It is key to achieving consistent {quality}, and also the key to measuring the quality of your content and whether it is working effectively for your readers. 

        section: Publishing

            In the end, of course, all content must be published in order to be accessible to readers. Publishing in a structured writing environment is complex, largely because so many of the other structured writing algorithms are actually executed during the publishing process. To facilitate this, most structured writing system implement a multi-step publishing process that allows different algorithms to be plugged in at the appropriate points in the process. This chapter will outline the partitioning of a structure publishing system, indicating were each of the other algorithms are executed in the process. 

            But publishing today is often about more than producing static outputs. In many cases, we publish active content, content that either shapes itself to the reader or allows the reader to manipulate it on the fly. All of the active content algorithms are actually the same structured writing algorithms we have already looked at, but publishing active content changes were they fit in the publishing process. And preparing for active content means structuring your content for the algorithms that will be used to generate the active content. This is another area in which the structured writing domain you have chosen, as well as the specific structures you have implemented will make a huge difference in what you are able to deliver to the reader.        

        section: Translation
            Finally, {translation} is a major source of complexity in many content systems. Translation deserves a book all to itself, but this chapter will show some of the basic ways in which structured writing, and the various structured writing algorithms, can make a big difference for translation quality and costs. 
