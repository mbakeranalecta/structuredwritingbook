<?xml version="1.0" encoding="UTF-8"?>
<chapter name ="chapter.repeatability">
<title>Repeatability</title>
<annotations>
<p>Concepts</p>
<p><phrase><annotation type="concept">subject domain</annotation></phrase> <phrase><annotation type="concept">media domain</annotation></phrase> <phrase><annotation type="concept">document domain</annotation></phrase> <phrase><annotation type="concept">management domain</annotation></phrase> <phrase><annotation type="concept">subject-domain</annotation></phrase> <phrase><annotation type="concept">media-domain</annotation></phrase> <phrase><annotation type="concept">document-domain</annotation></phrase> <phrase><annotation type="concept">management-domain</annotation></phrase> <phrase><annotation type="concept">hybrid markup language</annotation></phrase> <phrase><annotation type="concept">Every Page is Page One</annotation></phrase> <phrase><annotation type="concept">abstract language</annotation></phrase> <phrase><annotation type="concept">information architecture</annotation></phrase> <phrase><annotation type="concept" specifically="top-down information architecture">top-down</annotation></phrase> <phrase><annotation type="concept">metadata</annotation></phrase></p>
<p>Languages</p>
<p><phrase><annotation type="language">SAM</annotation></phrase> <phrase><annotation type="language">DITA</annotation></phrase> <phrase><annotation type="language">DocBook</annotation></phrase> <phrase><annotation type="language">Markdown</annotation></phrase> <phrase><annotation type="language">HTML</annotation></phrase> <phrase><annotation type="language">XML</annotation></phrase></p>
<p>Algorithms</p>
<p><phrase><annotation type="algorithm">authoring algorithm</annotation></phrase> <phrase><annotation type="algorithm">authoring</annotation></phrase> <phrase><annotation type="algorithm" specifically="composition">composability</annotation></phrase> <phrase><annotation type="algorithm">composition algorithm</annotation></phrase> <phrase><annotation type="algorithm">composition</annotation></phrase> <phrase><annotation type="algorithm">conformance algorithm</annotation></phrase> <phrase><annotation type="algorithm">conformance</annotation></phrase> <phrase><annotation type="algorithm">content management algorithm</annotation></phrase> <phrase><annotation type="algorithm">content management</annotation></phrase> <phrase><annotation type="algorithm">content reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">content reuse</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing</annotation></phrase> <phrase><annotation type="algorithm">encoding algorithm</annotation></phrase> <phrase><annotation type="algorithm">encoding</annotation></phrase> <phrase><annotation type="algorithm">exchange algorithm</annotation></phrase> <phrase><annotation type="algorithm">exchange</annotation></phrase> <phrase><annotation type="algorithm">extract and merge algorithm</annotation></phrase> <phrase><annotation type="algorithm">extract and merge</annotation></phrase> <phrase><annotation type="algorithm">formatting algorithm</annotation></phrase> <phrase><annotation type="algorithm">formatting</annotation></phrase> <phrase><annotation type="algorithm">linking algorithm</annotation></phrase> <phrase><annotation type="algorithm">linking</annotation></phrase> <phrase><annotation type="algorithm">presentation algorithm</annotation></phrase> <phrase><annotation type="algorithm">presentation</annotation></phrase> <phrase><annotation type="algorithm">publishing algorithm</annotation></phrase> <phrase><annotation type="algorithm">publishing</annotation></phrase> <phrase><annotation type="algorithm">quality algorithm</annotation></phrase> <phrase><annotation type="algorithm">quality</annotation></phrase> <phrase><annotation type="algorithm">relevance algorithm</annotation></phrase> <phrase><annotation type="algorithm">relevance</annotation></phrase> <phrase><annotation type="algorithm">rendering algorithm</annotation></phrase> <phrase><annotation type="algorithm">rendering</annotation></phrase> <phrase><annotation type="algorithm">reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">reuse</annotation></phrase> <phrase><annotation type="algorithm">separating content from formatting</annotation></phrase> <phrase><annotation type="algorithm">single source of truth algorithm</annotation></phrase> <phrase><annotation type="algorithm">single source of truth</annotation></phrase> <phrase><annotation type="algorithm">single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">single sourcing</annotation></phrase> <phrase><annotation type="algorithm">synthesis algorithm</annotation></phrase> <phrase><annotation type="algorithm">synthesis</annotation></phrase> <phrase><annotation type="algorithm" specifically="conformance">validation</annotation></phrase></p>
<p>Tools</p>
<p><phrase><annotation type="tool">content management system</annotation></phrase> <phrase><annotation type="tool">Content management systems</annotation></phrase></p>
<p>Roles</p>
<p><phrase><annotation type="role">information architect</annotation></phrase></p>
</annotations>
<index>
<record>
<type>algorithm</type>
<term>repeatability</term>
</record>
<record>
<type>concept</type>
<term>repeatability</term>
</record>
</index>
<p>Content is one of the hardest products to test. One of the biggest barriers to consistently producing quality content is being able to test that quality has actually been achieved – that is, that the content is serving and/or influencing the reader as you want it to do.</p>
<p>The problem has two parts. The first is that it is hard to observe the effect of content. You just aren’t there to watch people read it. The second is that even when you do get to observe the effect of content on the reader, how do you know what aspects of the content achieved the effect you observed? Making these observations on individual pieces of content is of limited value. Yes, you can do continual A/B testing, taking down content that does not perform well and continually trying other things until you finally create a piece of content that performs well. But then how do you reproduce that success with the next piece of content you write? How do you determine which aspects of the successful content contributed to its success and should be emulated in future content?</p>
<p>Measuring content is not like measuring minivans or cans of peas, where every example is supposed to be exactly alike. Every piece of content is supposed to be different. It is great to find that you have a successful ad or blog post or manual topic, but to repeat that success, you have to look beyond the particularity of an individual item to see what it has in common with other successful items. Some part of the success of individual items doubtless lies in the features they and they alone possess – your review of a Harry Potter movie is going to get more hits than your review of an art-house flop for reasons entirely unrelated to the quality of your reviews – but much of it also comes from meeting specific user needs in a highly accessible ways, and there is often a pattern to that that can be repeated. Did your review of Harry Potter get more or fewer views than the next site’s review? Do your reviews of art-house flops get more views than their’s? What is it about how you write your reviews that makes them more popular, regardless of the popularity of the movie? Maybe its your acerbic wit, of course, which is not easy for another writer to reproduce, but maybe it is that you present the information that movie goers really care about in a format that is clear and easy to read. If so, that pattern should be repeated across all your reviews. With recipes, maybe there is a pattern to a recipe that makes it particularly easy for a reader to choose which dish to prepare and to prepare it successfully, and those characteristics should be repeatable across a whole set of recipes. While literary charm doubtless counts for something – and for more in some forms of content than in others – saying the right things in the most accessible way is still the basic bread and butter of content quality, and structured writing is the best way to ensure that you can deliver that repeatably.</p>
<p>Trying to derive lessons from a single piece of successful content is little more than an educated guess. You are abstracting from a single data point. To be certain which aspects of the content are doing the most to achieve it aims, you need to observe multiple samples that exhibit the same basic features. It is when you observe that multiple pieces of content exhibiting the same features are all successful that you know with some degree of reliability that it is those features that make the content work. Once you know this, you are in a position to reliably produce new content that will be similarly successful. You have achieved repeatability.</p>
<p>To achieve repeatability, you need to partition those elements that you want repeated and constrain your authors to follow them. But is it is not enough to constrain content patterns after the fact, when you already know what works. If you don’t have many examples of the same pattern to test, you can’t draw any useful conclusions about which elements of the pattern are working and which are not. You not only have to constrain in order to repeat, you have to constrain in order to measure. Without constraints, you don’t know what you are measuring.</p>
<p>In order to generalize the measurements you are taking, so that you can draw conclusions that apply to more than one piece of content, you need to make sure that each piece of content you are measuring has the same structures and features. That is the only way you can measure if it is the structures and features, rather than the individual texts, that are performing well. You need consistent conformant content structures that express those features of a text that impact is quality. Until you have that, you have no reliable basis on which to extrapolate any measurements you do of individual pieces of content. In order to achieve repeatability in content creation, therefore, you need structured writing.</p>
<p>The most fundamental part of content quality is to give the reader the information they need in a form they can use. A confounding aspect of content quality is that every reader is different. They are doing different thing, they have different experiences, and they have different vocabularies.</p>
<p>For many writers in corporate environments, lack of knowledge about the readers, their tasks, and their backgrounds, is one of the biggest problems in determining what content is required and what form it should take. While direct contact with the customer is undoubtedly the best way to address this, you can actually learn what content to create without ever meeting the reader, as long as you can measure the performance of your content, generalize your results, and repeat the structures that perform best.</p>
<p>If the bread and butter of content quality is to provide the right pieces of information in the most accessible way, and if you have some means of measuring the impact of your content, then you can use strictly constrained patterns and testing to establish which set of information and which presentation of that information works best for your audience. While seeding this process based on knowledge of the reader is obviously to be preferred, ultimately, this is a the most reliable way to learn about what content works for your reader, even if you don’t actually know why it works.</p>
<p>Without known good patterns and reliable tests, only personal knowledge of the reader will help the individual writer craft content that may meet their needs. But this means that every writer is doing the reader research and the associated information design work every time, and with a limited body of information and few if any opportunities to test their design. If they spend the kind of time that is required to get this research and design work right, then this is a huge overhead for the organization, and a huge amount of repeated effort. If they don’t spend the time to do it right, then the content probably won’t meed the reader’s needs. As much as we talk about the potential cost savings of information reuse, the potential cost saving and quality improvement from the reuse of known good information design patterns verified by testing is enormous.</p>
<p>Organizations often look to content reuse as the principle source of cost savings in the content system. But as we have seen, content reuse can be quite expensive to implement. Cost savings are not guaranteed, and quality problem can result from an overzealous approach to reuse. Repeatability, which we can think of as the reuse of patterns rather than individual pieces of content, can be a huge time-saver, and one that, if applied correctly, can bring big quality gains at the same time. And the kinds of constrained patterns which provide repeatability also direct the complexity of information design away from contributors, opening the way to greater <phrase>collaboration</phrase> by bringing in authors who are experts in the subject matter but not information design, and who do not have the time or inclination to use complex content management or reuse systems. You should consider carefully whether repeatability, rather than reuse, should be the first place you should look to reduce costs in your content system.</p>
<p>Every structured writing domain provides support for repeatability within its domain. The use of a style sheet in a word processor ensure repeatability in the formatting of headings and lists. Document-domain languages like DITA and DocBook provide repeatability in document structures (but only to the extent that they constrain the use of such structures). To get repeatability in the rhetorical structure of content, however, you need to turn to the subject domain.</p>
</chapter>
