<?xml version="1.0" encoding="UTF-8"?>
<chapter name="chapter.design">
<title>System design</title>
<annotations>
<p>Concepts</p>
<p><phrase><annotation type="concept">subject domain</annotation></phrase> <phrase><annotation type="concept">media domain</annotation></phrase> <phrase><annotation type="concept">document domain</annotation></phrase> <phrase><annotation type="concept">management domain</annotation></phrase> <phrase><annotation type="concept">subject-domain</annotation></phrase> <phrase><annotation type="concept">media-domain</annotation></phrase> <phrase><annotation type="concept">document-domain</annotation></phrase> <phrase><annotation type="concept">management-domain</annotation></phrase> <phrase><annotation type="concept">hybrid markup language</annotation></phrase> <phrase><annotation type="concept">Every Page is Page One</annotation></phrase> <phrase><annotation type="concept">abstract language</annotation></phrase> <phrase><annotation type="concept">information architecture</annotation></phrase> <phrase><annotation type="concept" specifically="top-down information architecture">top-down</annotation></phrase> <phrase><annotation type="concept">metadata</annotation></phrase></p>
<p>Languages</p>
<p><phrase><annotation type="language">SAM</annotation></phrase> <phrase><annotation type="language">DITA</annotation></phrase> <phrase><annotation type="language">DocBook</annotation></phrase> <phrase><annotation type="language">Markdown</annotation></phrase> <phrase><annotation type="language">HTML</annotation></phrase> <phrase><annotation type="language">XML</annotation></phrase></p>
<p>Algorithms</p>
<p><phrase><annotation type="algorithm">authoring algorithm</annotation></phrase> <phrase><annotation type="algorithm">authoring</annotation></phrase> <phrase><annotation type="algorithm" specifically="composition">composability</annotation></phrase> <phrase><annotation type="algorithm">composition algorithm</annotation></phrase> <phrase><annotation type="algorithm">composition</annotation></phrase> <phrase><annotation type="algorithm">conformance algorithm</annotation></phrase> <phrase><annotation type="algorithm">conformance</annotation></phrase> <phrase><annotation type="algorithm">content management algorithm</annotation></phrase> <phrase><annotation type="algorithm">content management</annotation></phrase> <phrase><annotation type="algorithm">content reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">content reuse</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing</annotation></phrase> <phrase><annotation type="algorithm">encoding algorithm</annotation></phrase> <phrase><annotation type="algorithm">encoding</annotation></phrase> <phrase><annotation type="algorithm">exchange algorithm</annotation></phrase> <phrase><annotation type="algorithm">exchange</annotation></phrase> <phrase><annotation type="algorithm">extract and merge algorithm</annotation></phrase> <phrase><annotation type="algorithm">extract and merge</annotation></phrase> <phrase><annotation type="algorithm">formatting algorithm</annotation></phrase> <phrase><annotation type="algorithm">formatting</annotation></phrase> <phrase><annotation type="algorithm">linking algorithm</annotation></phrase> <phrase><annotation type="algorithm">linking</annotation></phrase> <phrase><annotation type="algorithm">presentation algorithm</annotation></phrase> <phrase><annotation type="algorithm">presentation</annotation></phrase> <phrase><annotation type="algorithm">publishing algorithm</annotation></phrase> <phrase><annotation type="algorithm">publishing</annotation></phrase> <phrase><annotation type="algorithm">quality algorithm</annotation></phrase> <phrase><annotation type="algorithm">quality</annotation></phrase> <phrase><annotation type="algorithm">relevance algorithm</annotation></phrase> <phrase><annotation type="algorithm">relevance</annotation></phrase> <phrase><annotation type="algorithm">rendering algorithm</annotation></phrase> <phrase><annotation type="algorithm">rendering</annotation></phrase> <phrase><annotation type="algorithm">reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">reuse</annotation></phrase> <phrase><annotation type="algorithm">separating content from formatting</annotation></phrase> <phrase><annotation type="algorithm">single source of truth algorithm</annotation></phrase> <phrase><annotation type="algorithm">single source of truth</annotation></phrase> <phrase><annotation type="algorithm">single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">single sourcing</annotation></phrase> <phrase><annotation type="algorithm">synthesis algorithm</annotation></phrase> <phrase><annotation type="algorithm">synthesis</annotation></phrase> <phrase><annotation type="algorithm" specifically="conformance">validation</annotation></phrase></p>
<p>Tools</p>
<p><phrase><annotation type="tool">content management system</annotation></phrase> <phrase><annotation type="tool">Content management systems</annotation></phrase></p>
<p>Roles</p>
<p><phrase><annotation type="role">information architect</annotation></phrase></p>
</annotations>
<index>
<record>
<type>task</type>
<term>system design</term>
</record>
</index>
<p>Unless you are writing directly on paper, chiseling into stone, or drawing letters by hand in a paint program, you are using structured writing techniques to create content. You are using tools that have been designed to partition and distribute some part of the complexity of content creation in some particular way, and you are observing a discipline, a set of constraints, imposed by that partitioning. It is not a matter of whether your system is structured or not, but how and for what purpose it is structured, and whether that purpose is being achieved.</p>
<p>The question you need to address, therefore, is whether your current partitioning is ensuring that all the complexity in your content creation process is being handled by a person or process with the skills, resources, and time required, or is complexity going unhandled in your system and getting dumped on the reader?</p>
<p>If not all of your complexity is being appropriately handled, if complexity is falling through to your readers in the form of quality problems, then the question becomes, how do you change your approach to structured writing to handle complexity better?</p>
<p>It is important not to approach this problem piecemeal. Complexity cannot be destroyed, only redirected, and every tool you adopt introduces new complexity which must also be partitioned and redirected appropriately. Attacking one piece of complexity in isolation usually results in complexity being directed away from the area you attack, but that complexity goes somewhere, and if you don’t think about where it goes, and how it will be handled there, you can easily end up with more unhandled complexity in your system than your started with.</p>
<p>The very fact that structured writing has the ability to move the complexity around the system, imposing it on one role at the expense of another, can lead to piecemeal rather than comprehensive solutions as different groups or different interests try to attack their part of the problem. For instance, there has been a long history of IT departments choosing content management systems on the basis that they were easy for the IT department to install and administer, only to have them be deeply unpopular with users because they pushed complexity out to writers and other users. On the other hand, some groups of writers want to write in uber-simple formats like Markdown, despite the difficulties that its limited structure and capabilities create for an overall publishing process. Everyone tries to simplify their own lives, heedless of the expense to others.</p>
<p>Here is the inescapable fact: complexity is irreducible. It can be moved but not destroyed. The only way to remove complexity from a process is to stop doing something. Actually, the first question you should ask in any assessment of your process, is what things you are doing that you should simply stop doing. What is not creating any value? But let’s assume that you have done that. Now that you have stopped doing things that you did not need to do, simplifying one function, will always move complexity somewhere else in the system. Moving complexity somewhere else in the system is fine if it is moved somewhere where it can be handled by an appropriate person or algorithm. The point is not to eliminate complexity, but to make sure it is handled correctly. The enemy is not complexity itself, it is unhandled complexity.</p>
<p>How do you design a content system that ensures that all complexity (or as much of it as is reasonably possible) is handled by a person or algorithm that has the time, skills, and resources to handle it? You start by understanding the sources of complexity in your content system.</p>
<section>
<title>Identifying complexity</title>
<p>Where is the complexity in your content system? It is different for every organization. While the basic functions of content development are the same for everyone, the amount of complexity they generate differs greatly depending on your needs and circumstance. If you translate into 35 languages for example, translation generates more complexity in your content system than in the system of an organization that translates to one language, or to none. If you have a complex product line in an industry with a complex vocabulary, terminology control creates far more complexity in your system than for someone with a simple consumer product. In order to know where you need to partition and redirect complexity, you need to identify where the biggest sources of complexity are in your content system. Here are some places to look:</p>
<section>
<title>Current pain points</title>
<p>Inconsistency, duplication, delay, error, and failure are escape valves for unhandled complexity. The complexity underlying these problems can be hard to see, even when it is causing pain. Familiarity with your current process may make it difficult to see that things could be different. Seeing that there is another possible way to do things often provides the insight into the hidden complexity of the current process. Hopefully the chapters in this book on the structured writing algorithms and the different ways that they are handled will help you see your current processes in a different light, and therefore help you to identify the complexity in them, and assess whether it is being adequately handled.</p>
<p>In order to find the true source of the complexity, however, you may have to work your way upstream from the place where the problem is manifest. Ultimately, all unhandled complexity finds its way to the reader, so quality problems are usually the place that complexity will show up if it is not being handled properly. The other place that you may find the impact of complexity is in processes that seem too expensive or in staff that seem overburdened or burnt out.</p>
<p>Let’s say that you observe a quality problem: readers are getting lost in the content. They find an initial page, but they need more information on the concepts it mentions. But when they search, they end up back at the same page. What is the root cause of this problem? It could be one of (at least) three things:</p>
<ol>
<li>
<p>The information on the page is incomplete. The information should be there, but it’s not.</p>
</li>
<li>
<p>The content they need is not in the content set anywhere because no one realized it was needed.</p>
</li>
<li>
<p>The content they need is in the content set but they can’t get to it because there is no link to it from the page they are on.</p>
</li>
</ol>
<p>If you determine that the first issue is to blame, then the complexity that is going unhandled is that of determining the reader’s needs on a particular subject and making sure that it is always present in topics on that subject. You have a <phrase>repeatability</phrase> problem.</p>
<p>If the second issue is the problem, then it is the complexity of content planning that is not being handled. You may need to improve your <phrase>audit</phrase> capability.</p>
<p>If the third issue is the problem, then it is the complexity of managing and expressing the complex relationships between subjects that is not being handled. Perhaps the authors are not aware of the relationships, in which case you may have a rhetorical structure problem. Or perhaps they are aware but the cost of creating and maintaining links is too high, so they are skimping on linking. In this case you may need a different approach to <phrase><annotation type="algorithm">linking</annotation></phrase>.</p>
<p>Be careful when you do this analysis not to fall into two common pitfalls:</p>
<ul>
<li>
<p>Don’t stop your analysis too soon, and don’t be blinded by the limits of your current process. Trace the problem back to the actual source of complexity, independent of any tool or process considerations.</p>
</li>
<li>
<p>Don’t stop with the first big chunk of complexity you find and rush off to buy a tool to address it. You need to identify all the source of complexity in your system and come up with a comprehensive plan to manage all of them, otherwise you will just move complexity around, while adding tool complexity to the mix. You can easily end up worse off that you were before. Even your biggest hot-button issue may demand a very different solution once you have figured out the total complexity picture in your system and the overall best way to partition and direct that complexity.</p>
</li>
</ul>
</section>
<section>
<title>Unrealized possibilities</title>
<p>Chances are that there are things you don’t do today because they are not possible with your current tools, or any of the tools you are used to. It is easy to overlook these unrealized possibilities altogether because everyone else is dealing with the same tool limitations, meaning you may not see these possibilities realized elsewhere. But don’t let the designs you can conceive be limited by the designs your current tools can execute. Those limitation just point to a design complexity that you don’t currently have the means to handle.</p>
<p>A comprehensive bottom-up linking strategy is a good example of unrealized possibilities. If you are working in the document domain, and using document domain or management domain linking techniques, the then creation, management, and updating of links is expensive and complex to execute. In reaction to that complexity, you minimize the links you create, or create them in sub-optimal places. That complexity manifests itself as unrealized potential.</p>
<p>But if you switch to subject-domain linking based on subject annotations, you partition and distribute the complexity of linking away from authors and towards an algorithm, radically reducing the barriers to a comprehensive linking strategy and allowing the possibility of that design to be realized. (And note that you don’t have to go to a full <phrase><annotation type="concept">subject domain</annotation></phrase> system to use this approach to linking. It works just as well with subject annotations in otherwise <phrase><annotation type="concept">document-domain</annotation></phrase> information types.)</p>
</section>
<section>
<title>What’s working now</title>
<p>Some parts of your current system are working well, successfully partitioning and directing complexity to the right people or processes. You still need to inventory this complexity to make sure it is still handled well in your new process. (But don’t assume that because you are satisfied with this part of your current process that it is actually working optimally – you may just be settling for what you are used to.)</p>
<p>For instance, if you are generating reference information from source code using a tool like <phrase>Doxygen</phrase>, that is a complex task that is currently being handled by an algorithm. Make sure you add that to your inventory so that when you design your new system you don’t end up with that complexity no longer being handled properly.</p>
<p>At the same time, look around the edges of your current success stories to see if there is any unrealized potential there. Suppose your generated reference is being published through a different tool chain so it looks different and is not linked from or to the rest of your content. The is integration complexity that is going unhandled and falling through to the reader in the form of less usable content.</p>
<p>You may end up completely changing the way you handle the complexity you are successfully handling now in order to better distribute complexity across the whole system. But don’t loose sight of the complexity just because you are currently handling it well.</p>
</section>
<section>
<title>Complexity that impacts others</title>
<p>More difficult to identify are points where the impact of complexity is falling on someone else. These are the pains you are not feeling because someone else is suffering the consequences. Often this is the reader, but it could be others in your organization – support, sales, field engineering, etc.</p>
<p>For instance, if you are asking developers to contribute content to your documentation set, but you are working in a complex document domain or media domain tool that the developers don’t have the bandwidth to learn, you could be dumping a lot of authoring complexity on them.</p>
<p>You may get push back from the developers saying that if they are going to contribute, they are only willing to do so in <phrase>MarkDown</phrase>. This is another case of the deflecting complexity onto someone else, since <phrase>MarkDown</phrase> may not give you the structure and metadata you need to integrate the content with your publishing system.</p>
<p>Here you have a <phrase>functional lucidity</phrase> problem. The complexity of integrating content into an overall content set is not being sufficiently partitioned and directed away from the occasional contributor. Chances are there is also a <phrase>rhetorical</phrase> problem here: developers not knowing what information it actually needed, and not being given any rhetorical guidance. The solution may be to provide them with a specific <phrase><annotation type="concept">subject domain</annotation></phrase> format that precisely specifies the content required. The developers may be willing to use and learn this format (if its <phrase>functional lucidity</phrase> is good) precisely because it makes their lives easier by redirecting rhetorical complexity away from them.</p>
</section>
<section>
<title>Process overheads</title>
<p>Communication overhead is a huge source of complexity. Desktop publishing (DTP) was revolutionary in its day mainly for eliminating communication overhead between writers, designers, and typesetters by combining the three jobs into one. There is a huge benefit to developing interfaces that reduce the need for communication between collaborators. If the writer is thinking visually then giving them the tools to execute their visual ideas removes the need for communicating with a designer and a layout artist.</p>
<p>There are other approaches to handling this communication overhead. The document domain approach is to try to get the writer to think in terms of abstract document structures rather than formatting (separating content from formatting). Tactically, this is the exact opposite of how DTP partitioned things, but strategically it has the exact same objective – to eliminate the communication overhead between writers, designers, and production people, and its attendant costs. The <phrase><annotation type="concept">document domain</annotation></phrase> approach further speeds up the process by handing the formatting to an algorithm, but introduces more abstraction into your system and transfers complexity to the person who writes the formatting algorithm.</p>
<p>The DTP approach dumped the formatting and production complexity on the Author, who now became designer and layout artist as well as writer. The document domain approach distributes the design complexity to the coder of the formatting algorithm and the execution of that design to the algorithm itself. No complexity has been removed, just redirected. And new complexity has been introduced because the author now has to learn the correct document domain structures to use. This complexity can be redirected again by moving to the subject domain, where the author write in a simpler, more concrete format where these choices are easier to make.</p>
<p>Any part of your process that is cumbersome, any part where information is being lost or work is having to be done twice, or where things slow down or bottlenecks occur is a place were complexity is hiding.</p>
</section>
<section>
<title>Your style guide</title>
<p>Traditionally, a style guide has been the dumping ground for complexity. Every new rule and requirement created in response to a content problem gets written into an ever growing style guide. This complexity is not actually being handled, it is merely being dumped on the writer. But the style guide quickly grows beyond the capacity of any writer to remember or follow it in every word they write. The rules are not followed and the complexity falls through to the reader.</p>
<p>This is not to say that there is no need for a style guide. There are style issues that cannot be effectively factored out and these the writer will have to deal with, and will need guidance to deal with consistently. But the writer’s ability to conform to these stylistic constraints will be directly proportional to their number. Using structured writing techniques to redirect as many style issues as possible away from the author (and thus the style guide) increase the conformance to those issues that cannot be partitioned or directed away.</p>
<p>Taking your style guide and simply going though it looking for rules that you could factor out by moving content to a different domain is a great way to inventory the complexities in your system.</p>
</section>
<section>
<title>Change management issues</title>
<p>The growth in unhandled complexity will often be interpreted (especially by the advocates of a system you have just installed) as a change management problem or a training problem. But while change management and training are both necessary any time you change how you do things, the most likely cause of problems after the installation of a new system is design problems, specifically a system design that redirects complexity away from itself without consideration for how it is going to be handled.</p>
<p>Change management is a scapegoat for process complexity that no one will own. It is very common to blame the failure of structured writing systems on unwillingness of writers to change. The cure, the backers of the system assure us, is more training and more generalization of the change. But what is usually going on in these cases is that the system design has dumped new and unmanageable complexity on whatever group is rebelling – almost always the writers, either the full time writers or the occasional contributors.</p>
</section>
<section>
<title>What’s coming down the road</title>
<p>The world is in the middle of a transition from paper to hypertext.<citation type="idref" value="hypertext"/> This involves three types of complexity. First, the complexity of architecting information and publishing to paper. Second, the complexity of architecting information and publishing it to hypertext. Third, the complexity of transitioning your content processes from exclusively focusing on paper and paper equivalents (such as PDFs) to either publishing to both or only to hypertext.</p>
<footnote id="hypertext">
<p>I say hypertext here rather than web because the web is both a delivery vehicle and a information architecture. You can publish to the web by sticking a PDF on a server. This is not hypertext. On the other hand, there are hypertext media that are not on the web, such as hypertext CD-ROMs or help systems. In terms of creating complexity in the content system, it is hypertext, not the Web itself, that makes a difference. Hypertext requires a different approach to <phrase>rhetoric</phrase> and <phrase><annotation type="concept">information architecture</annotation></phrase> and involves major differences in the <phrase><annotation type="algorithm">linking</annotation></phrase> and <phrase><annotation type="algorithm">publishing</annotation></phrase> algorithms compared to paper.</p>
</footnote>
<p>Almost every organization currently has to produce both, but most are not doing both well. As we noted in <citation type="nameref" value="chapter.single-sourcing"/> and <citation type="nameref" value="chapter.architecture"/>, there are major differences in how you write, organize, present, and format content for paper and for hypertext, and differential single sourcing requires different tools and techniques than are found in most single sourcing tools today. Most tools essentially allow you to design for one media and then do a more or less best effort attempt to transfer that design to the other media.</p>
<p>This means that in practice, whether you acknowledge it or not, you have a primary media and a secondary media. And while there are differential single sourcing techniques that can improve your ability to address each media separately, there are limits to what you can do to address both media without rewriting content to fit a different information architecture. In short, unless you are planning to go Web only (and some organizations are Web only for a large part of their content) then you do have to choose a primary media.</p>
<p>If your current primary media is paper, and if your future primary media should be hypertext (which it should in many cases today) then you need to consider the complexities of your chosen primary media as well as the complexities of the the differential single sourcing you will need to do to address your secondary media appropriately.</p>
<p>Shifting to a new primary or exclusive media can also remove some complexity from your system. <phrase>Reuse</phrase>, for instance, is a much bigger issue in the paper world than in <phrase>hypertext</phrase>, where you can link to common material rather than including it inline. Single sourcing, and differential single sourcing in particular, are larger issue in the transition period than they will be if and when you stop producing paper formats. Linking and the techniques of a bottom-up information architecture, on the other hand, belong to the hypertext world and are likely to grow in importance as you turn more of your focus to the web and online media.</p>
<p>If you choose your tools and your structures primarily on the basis of the needs of the paper world or the transition period, you are likely to find yourself going through a similar upheaval in just a few years when the transition to hypertext catches up with you.</p>
</section>
</section>
<section>
<title>Partition and direct complexity</title>
<p>Once you know where your major sources of complexity are, and have a good idea of what that complexity costs you in terms of process and quality, it is time to decide how your want to partition and divide that complexity, and to choose the structured writing techniques that will achieve that partitioning.</p>
<p>In some cases, we reduce the complexity that falls on each contributor by gathering a particular complex operation from the many and distributing it to one uniquely qualified or equipped person. For example, when we <phrase>separate content from formatting</phrase> we take formatting responsibility away from all writers and distribute it to a single designer who writes the formatting algorithm. In other cases, we do so by taking a complex operation currently being performed by a single person and distribute it out to many contributors. For example, linking is typically the sole responsibility of the writer writing the piece that contains the links. But the subject-domain approach to linking, which uses subject annotation rather than link markup, partitions and distributes the linking task three ways. The writer identifies significant subjects in their text. Other writers index or structure their content so that its subject matter can be identified clearly by algorithms, and the information architect or content engineer writes the linking algorithm (or may implement some other way of handling the subject affinity in the content). In another example, the bottom up approach to taxonomy management partitions and distributes the task of terminology discovery out to the writers while distributing terminology management to a taxonomist.</p>
<p>As is no doubt clear by now, I regard the heart of this process to be partitioning and directing complexity away from writers. Writers are the principle source of value in a content process. Writing is an activity that requires full attention, and so any complexity that the writer has to deal with while writing is diminishing the available attention they have for writing itself, which will always result in compromises to content quality. Achieving functional lucidity for writers should be the first priority of your content management system design.</p>
<p>Because attention is a limited resource, there is value in partitioning and distributing tasks even when you perform all of the tasks yourself. Partitioning the tasks allows you to give your full attention to each individual task and thus perform better than you could if your tried to divide your attention between them while performing both at once.</p>
<p>But functional lucidity is not a fixed or universal thing. It depends very much on the writer, their background, and their skill set. It also depends, to a certain extent, on the nature of the writing task. Functional lucidity for creating entires in a reference is different for functional lucidity for creating a slide deck or an essay on the fundamental architecture of a product. Familiarity and frequent practice of an activity reduces the amount of attention it requires to do it well, so a full time professional technical writer may be able to effectively manage far more content management tasks and may need less rhetorical guidance than an occasional contributor. On the other hand, a full time writer might need more rhetorical guidance than a subject matter expert for creating highly technical material, because they don’t understand the technology or the reader’s task as well. No matter how much complexity your writers can handle, however, they will always benefit from a system that maximizes functional lucidity, and partitions and directs away any form of complexity that is not germane to their ability to write the content they are supposed to produce.</p>
<p>That said, there are times when you should direct complexity toward writers. As we saw when we looked at terminology management, writers are the ones on the front line who best understand how terminology is being used and what subject your terminology needs to cover. A terminologist, however skilled, as less access to that information on a daily basis and could easily miss the some of the subtitles that need to be expressed, or the local terms that communicate those subtleties most effectively to a particular audience. Subject annotation partitions discovery towards the writer (without actually adding any complexity, if they are already doing subject annotation for other reasons) and supports the distribution of conformance checking and decision making towards the taxonomist.</p>
<p>A good principle, therefore, is to always partition and direct complexity toward expertise. If the expertise is distributed, direct it outwards. If it is centralized, direct it inwards. Bottom up taxonomy, for instance, partitions language choices towards writers while allowing discovery and conformance to flow back to taxonomists.</p>
<p>In many cases, you want to direct complexity to algorithms. This means that you need to clarify the exact rules that the algorithm is to follow, and sometimes that means partitioning the complexity carefully so that you carve out the processes that follow consistent rules from those that require individual human attention.</p>
<p>The use of <phrase><annotation type="concept">subject-domain</annotation></phrase> annotations to drive linking is a good example of this. The task of finding a resource to link to for every significant subject mentioned in a content set is a complex and tedious one, and is it made much worse in an environment in which content is changing all the time and has to be continuously published. But the basic rules for link discovery are actually quite consistent. Where subject X is mentioned, create a link to the best resource or resources on subject X. The problem is one of identification. How do you identify the subject that is worth linking to, and how do you identify the best resources on that subject?</p>
<p>Where links are formed by hand, these are complex, time consuming tasks. But the the use of subject annotation, combined with the indexing of topics by their subject, provides algorithms with the information they needs to do the discover accurately. Actually, there is a wrinkle to this. Without terminology control for how you talk about significant subjects, simply naming the subjects might not be enough for an algorithm. Too many subjects and topics might be misidentified due to inconsistent naming or ambiguous names. By adding type information to subject annotations (such as identifying “Rio Bravo” as a reference to a movie) we remove the ambiguity and lay the groundwork for appropriate terminology management. This is a complicated piece of complexity management and partitioning, but the result is that we remove a lot of complexity from authors while greatly improving linking, change management, and terminology management.</p>
<section>
<title>Focus on complexity, not effort</title>
<p>Complexity is by no means the same thing as effort. Structured writing systems that are well designed to support appropriate algorithms can reduce overall effort considerably, while significantly improving quality. But where they place complexity matters. Even if a task requires less effort, adding complexity to it changes how the person assigned to that task works, and how they need to be qualified and trained. It is important to appreciate how the distribution of complexity and effort in the system you choose affects the dynamics and composition of your team.</p>
<p>In the end, the question of where complexity is distributed in your system is at least as important, if not more so, than the question of how much effort is avoided. The wrong distribution of complexity can not only undermine quality, it can also undermine the attempt to reduce effort. Complexity in the wrong place not only undermines the productivity of those saddled with it, it also undermines the reliability of every other algorithm, thus undermining the attempt to reduce effort and cost in those algorithms.</p>
<p>Distributing complexity away from writers is key because when structured writing systems distribute complexity toward writers, they don’t merely add a new and complex task that must be learned, they impose that complexity directly on the activity of writing itself. More complexity than the writer can handle will not only effect the quality of the content they produce, it will also affect the correctness of the structures that they create. The algorithms that reduce effort rely on accurate content structures. If overloading writers results in poor content structures, then the algorithms will not work properly, and that will result in more effort to fix things.</p>
<p>A focus on reliable handling of complexity, therefore, will likely result in a greater and more reliable reduction of effort than a direct assault on effort itself. Indeed, it is sometimes worth investing in activities that seem like additional effort, such as creating structures and algorithms to improve repeatability and conformance, or creating specific subject domain structures for a new subject to be documented, rather than knocking the content out in a generic document domain format. Avoiding this up front effort may seem like a win, but in many cases the amount of down-stream effort that will be created by less reliable content and algorithms may be far greater.</p>
</section>
<section>
<title>Indivisible complexity</title>
<p>There are complex tasks which by their very nature have to be done by one mind. It is important to respect this indivisible complexity when planning your content system. Splitting functions that belong together, such as writing semantic blocks and combining them into sound readable rhetorical blocks, can cause severe quality problems. Remember that the partitioning of complexity always requires that you create a structure that transmits all of the information required to handle the information you are passing to the next partition. If too much information is required, then you are not reducing the complexity of the task in the first partition, and if information cannot be easily expressed in a standard way, chances are you are letting complexity fall through the cracks.</p>
</section>
<section>
<title>Subtract current tool complexity</title>
<p>As we have noted, all tools introduce complexity into the content system. We choose them because they allow us to partition and distribute complexity better, including their own complexity. But when you are inventorying the complexity of your system, the complexity introduced by your current tools should not be part of the inventory. Those tools may be going away are a result of your system redesign, so their complexity is not part of the inventory of the inherent complexity in your content system.</p>
</section>
<section>
<title>Avoid tool filters</title>
<p>When designing any process it is important not to see things through the filter of your current tools. Every tool reflects the tool-designer’s view of how some or all of the complexity of the content system should be partitioned and directed. And since the partitioning and directing of the complexity of a system is the definition of process, tools are encapsulations of process. When you buy a tool, you buy the process it encapsulates, and long practice with the tools can shape how you view process. After a while, it is hard to imagine a process in any other terms.</p>
<p>Thus all too often when we spec a new tool, we essentially end up specking our old tool with some particular improvement we think will make our lives better. But many cases, the improvement we are seeking is not compatible with the current tool. (If it were, the vendor would probably have included it in their ongoing attempts to drive upgrade sales through new features.) If your old tool won’t cut it, chances are you need a different process from the one incorporated in that tool, and you are going to need to break through your tool filter to envision a new process. This is why this book has focused on algorithms and structures, not tools and systems: to help you overcome the tool filter in your process design decisions.</p>
<p>Over the years I have seen many requirements documents for proposed structured writing systems that essentially said that the proposed system must work exactly like Microsoft Word. This is not surprising when the people writing the requirements have used nothing but Word to create content for years. The tools you know shape how you work and what you think of as possible. As Henry Ford is supposed to have said of the Model T, “If I asked customers what they wanted, they would have said faster horses.” Even when we are dissatisfied with our current tools, we tend to want the same basic tool only more so. This is why so many structured writing tool vendors literally advertise that their editor looks and feels “just like Microsoft Word”. (Not to mention those vendors who create tools that modify Word itself.)</p>
<p>But Microsoft Word is a tool that sits on the boundary between the <phrase><annotation type="concept" specifically="media domain">media</annotation></phrase> and <phrase><annotation type="concept">document domain</annotation></phrase>s. Using Word itself, or something that looks like Word, is usually an attempt to move its use slightly more into the document domain, but as we have seen, the WYSIWYG authoring interface invites a slide back into the media domain by hiding the structure that is supposed to be created and showing only the formatting that is supposed to have been factored out in adopting the document domain.</p>
<p>It is not surprising, then, that the structured writing tools that have been popular in the market to date have been predominantly document domain tools, and have tended, like DocBook, to be very loosely constrained. (It is much easier to write an XML document in a WYSIWYG editor if the underlying structures are minimally constrained, since it lets you insert whatever bit of formatting you want anywhere you want, just as in Word.</p>
<p>Even with tools like DITA, which, while it is still fundamentally a document domain system, is more constrained, and capable of being constrained further, tend to be used in its generic out of the box form and with a Word-like WYSIWYG interface.</p>
<p>Thus even when a decision-making process is based on business requirements rather that specific tools, it is often tacitly driven by existing tool sets and ways of doing things, because those existing tools and processes shape our view of what the business requirements actually are. We don’t ask for a better way to get from DesMoins to Albuquerque, we ask for a faster horse that eats few oats. This is why it is important to forget about your current tools and their associated processes and to focus on the sources of complexity in your system and how you can partition and distribute that complexity effectively.</p>
</section>
</section>
<section>
<title>Select domains</title>
<p>Once you have a good idea of where the complexity lies in your content system and how you would like to partition and direct that complexity, it is time to decide which domains you want to work in. This is not as simple as picking one of the three and using it for everything. There are some pieces of content for which no meaningful subject domain markup makes sense – content that has no repeatable pattern of either subject matter or rhetoric. For this you will need generic markup in the document or media domain. Some content will need to be laid out by hand with an artists eye for design. That can only happen in the media domain. In practice, your content system is likely to include a mix of subject domain, document domain, and media domain content, with some measure of the management domain thrown in where needed. In fact, major public languages like DITA and DocBook contain structures from all four domains.</p>
<p>Also, the places where complexity is hurting your content is not necessarily the same for all content types. The complexities that attend the maintenance of a reference work are likely to be different from those that attend the creation of a full color print add in five languages. Different types of content requires different partitioning and direction of complexity, and so require different structures from different domains.</p>
<p>Ideally, the choice of domains would be simple. Given the complexities you have identified for partitioning and redirection, choose the domain that accomplished the desired partitioning. But in practice it is more complicated than that because structures and the algorithms that process them are themselves sources of complexity. For example, it may seem like <phrase><annotation type="language">DITA</annotation></phrase> addresses the complexities of your content reuse problem. But it also introduces complexities into the authoring process, in the form of complex markup and management domain intrusions. It also introduces significant content management complexity, both because it produces so many small artifacts, and because writers need a way to find reusable content. This creates a retrieval problem, which creates terminology management complexity. Handing these new complexities requires new tools, typically a DITA-aware structured editor and a DITA-aware <phrase><annotation type="tool">component content management system</annotation></phrase>, as well as new roles and extensive training. And even with those things in place, there is still a lot of conceptual and management complexity that writers have to deal with, and you still have issues with rhetorical conformance because there is no way to constrain rhetorical blocks larger than a DITA topic.</p>
<p>All of that additional complexity, and the cost of the tools, may be worth it if you can realize big enough gains from reuse without falling into its quality traps. For many organizations, it is the additional savings from reduced translation costs that swing the needle to the positive side, rather than reuse benefits alone. But some organizations have reported that they simply don’t realize the amount of reuse that would justify the expense and complexity of their DITA systems.</p>
<p>DITA provides every document/management domain reuse algorithm in the book, but at a high cost in additional complexity. You might find you are better off with reuse systems that don’t impose the kind of information typing constraints that are fundamental to DITA or simple document domain systems that provide a less comprehensive suite of reuse features but inject less complexity into your system. Or they might be better off with <phrase><annotation type="concept">subject domain</annotation></phrase> reuse tactics, which are less comprehensive than DITAs document/management domain tools provide, but actually remove complexity from the writer rather than adding it, improving both functional lucidity and conformance. It is usually better to optimize for the overall management of complexity across the system as a whole rather than to optimize one function at the expense of others.</p>
<p>Another source of complexity in the choice of domains is the amount of development you will have to do in house in order to implement them. <phrase>Media domain</phrase> tools like <phrase>Frame Maker</phrase> and public <phrase><annotation type="concept">document domain</annotation></phrase> tools like <phrase><annotation type="language">DocBook</annotation></phrase> and off-the-shelf <phrase><annotation type="language">DITA</annotation></phrase> come with ready-made structures and algorithms. To implement a subject-domain strategy that is specific to your own content, you will have to develop some structures and algorithms yourself. This obviously adds a level of complexity to your process.</p>
<p>I should stress that even with <phrase><annotation type="concept">media domain</annotation></phrase> and public <phrase><annotation type="concept">document domain</annotation></phrase> tools, you will almost certainly have to do some structure and algorithm development, probably on an ongoing basis. Developing and maintaining <phrase>FrameMaker</phrase> style sheets is structure and algorithm development, and many organization end up using tools like <phrase>FrameScript</phrase> to transfer mundane formatting or management tasks from writers to algorithms. If you want your DITA or DocBook output to match your brand, you are going to have to rewrite the formatting algorithms to create the look you want. And if you do any kind of DITA specialization or DocBook customization, you are going to be in full structure and algorithm development mode, requiring all the same skills that would be needed to develop your own <phrase><annotation type="concept">subject domain</annotation></phrase> structures and algorithms.</p>
<p>As we have seen throughout this book, the <phrase><annotation type="concept">subject domain</annotation></phrase> provides the most comprehensive set of structures and algorithms for addressing a wide range of structured writing algorithms. In particular, it does the best job of partitioning and directing complexity away from writers, which potentially open your system up to a wider range of contributors. It also provides for higher levels of conformance, which in turn means more reliable algorithms. And with the <phrase><annotation type="concept">subject domain</annotation></phrase>, most algorithms work on the same set of structures, as opposed to the <phrase><annotation type="concept" specifically="document domain">document</annotation></phrase> and <phrase>management domains</phrase>, in which each algorithms requires new structures. Finally, while there are more of them, subject domain structures tend to be small with few permutations of structure, meaning that their algorithms have less complexity to handle. All this helps contain development complexity.</p>
<p>Nonetheless, an organization that is looking to address the complexities of creating a bottom-up information architecture, for instance, might identify the <phrase><annotation type="concept">subject domain</annotation></phrase> as the best way to build such an architecture, but conclude that, for them, writing and maintaining the necessary structures and algorithms was too much complexity to introduce, and might decide to go with a Wiki or a <phrase><annotation type="language">Markdown</annotation></phrase>-based solution. This would throw more of the responsibility for linking and for repeatability onto writers, but that might be the right balance to strike in how complexity is partitioned and directed in that organization. (Scale can play a big role in this decision. At a large scale, managing linking and repeatability by hand becomes onerous, while developing and maintaining <phrase><annotation type="concept">subject domain</annotation></phrase> structures is amortized over a lager body of content.)</p>
<p>We can usefully map the various content management domains in terms of two properties, complexity and distribution. Complexity measure the size of a language and its level of abstraction. Distribution measures the number of different languages required to represent a set of content.</p>
<insert item="../graphics/domainmap.xml" type="image"/>
<p>The big public <phrase><annotation type="concept">document domain</annotation></phrase> markup languages like <phrase><annotation type="language">DITA</annotation></phrase> and <phrase><annotation type="language">DocBook</annotation></phrase> are by far the most complex. Complexity is not merely a matter of the number of different elements in their schemas. It is also a matter of the number of different combination or permutations of those elements that are allowed. If, as is common, there are dozens of different elements you can insert at many points in their document structures, than writers have to understand those permutations and their consequences and information architects and content engineers have to anticipate all of the possible permutations in the algorithms they write. Because of their size and their loose structure, there is very little you cannot express in these languages, but they are also a huge source of complexity that is often difficult to partition and redirect successfully. Simpler document domain languages are less complex but also less capable. There are document design that simply cannot be executed in <phrase>MarkDown</phrase>, for instance.</p>
<p>However, the upside of the document domain is that it is very homogeneous. You can express just about any document design with <phrase><annotation type="language">DocBook</annotation></phrase> or <phrase><annotation type="language">DITA</annotation></phrase>. This does not mean that they support an efficient partitioning and redirecting of content system complexity, it simply means that, other than very layout-specific designs that can only be executed in the <phrase><annotation type="concept">media domain</annotation></phrase>, you can produce just about anything in either one of these languages. This is obviously appealing in the sense that it requires only a single tool set and a single set of training. However complicated the tools and the training may be, and however much this may limit effective participation of occasional contributors, it is at least only one thing to worry about.</p>
<p>The media domain, by contrast, is both moderately complex and moderately diverse. At the core of its diversity is the paper/hypertext divide. But there are multiple forms of paper (including virtual ones like e-books) and multiple forms of online media. (The initial motivation for most structured writing, <phrase><annotation type="algorithm">separating content from formatting</annotation></phrase>, is to publish to more than one of these forms.)</p>
<p>The move away from the media domain accelerated as we entered the transition phase between paper and the hypertext. Most organizations prior to the beginning of this shift delivered only to paper and therefore could work in the media domain without problems. (Though, obviously, without the assistance of algorithms in handling many other functions in the content system.) But while there is no sign that paper and paper-like e-media are going away entirely, we have now reached the point where more and more content is being created and delivered only on the Web. Thus the use of media domain tools, and of simple document domain tools like <phrase>MarkDown</phrase> that are specific to the presentation needs of one media, are gaining in popularity. Again, the use of the media domain cuts you off from the assistance of algorithms in all other parts of the content process, but it is increasingly viable thanks to so much of information delivery once again being single-media.</p>
<p>The subject domain is far simpler than the media domain or the document domain. Our recipe markup is far simpler than even Markdown. But the subject domain is far more diverse. There are hundreds of different subjects, each with their own unique structures. And presenting the same subject to different audiences may also require a different subject domain structure. Obviously you don’t need all the subject domain structures in the world. You only need enough to cover your subject matter for your audience, but that will still be more structures that if you has chosen to write in the document domain or the media domain.</p>
<p>On the other hand, most subject domain structures are very simple. Being simple does not necessarily mean that they have a small number of elements, though that is almost always the case. It also means that there are few permutations of those elements, which makes it very much easier to validate and process these documents. Because subject structures are concrete rather than abstract, and use the language of the subject matter, they tend to be clear and intuitive to writers. Writers need little or no training to use them. And they can often be expressed in lightweight syntax, removing the need for expensive editors.</p>
<p>However, their diversity is itself a source of complexity. It means that you can’t buy structures and algorithms off the shelf. You have to create and maintain them for yourself. This does not mean maintaining a complete custom publishing tools chain. You only have to manage the processing from <phrase><annotation type="concept">subject domain</annotation></phrase> to <phrase><annotation type="concept">document domain</annotation></phrase>. You can make any public <phrase><annotation type="concept">document domain</annotation></phrase> language your <phrase><annotation type="concept">document domain</annotation></phrase> layer, and use the existing tool chain for that language for the rest of your publishing systems. (By extension, this means that if you already have a <phrase><annotation type="concept">document domain</annotation></phrase> system in place, you can add a <phrase><annotation type="concept">subject domain</annotation></phrase> layer on top of it without changing the rest of the system.)</p>
<p>Creating and maintaining subject domain structures and algorithms is relatively simple, because the structures themselves are simple and well constrained with few permutations. It is also made significantly simpler because most structured writing algorithms are supported by the same <phrase><annotation type="concept">subject domain</annotation></phrase> structures, unlike the document/management domain, where each algorithm requires different structures. And because it has good functional lucidity, the <phrase><annotation type="concept">subject domain</annotation></phrase> tends to produce more reliable structures, so there are fewer error conditions to worry about. With a good architecture that partitions the publishing process well, there should be few side effects to worry about.</p>
<p>However, the need to add new structures and algorithms will occur from time to time and will have to be met fairly rapidly when it occurs. This means that you need to keep this information architecture/content engineering capability available to your organization. This may not be as onerous a requirement as it sounds, because the truth is that you will find that there are similar requirements for a large <phrase><annotation type="concept">document domain</annotation></phrase> system as well, but is it definitely a source of complexity in a <phrase><annotation type="concept">subject domain</annotation></phrase> system.</p>
<p>Ultimately, then, there is no one right domain that everyone should be working in, and certainly no one right tool that everyone should be using for content creation. Rather that are three (plus one) domains of structured writing each of which offers different capabilities for partitioning and directing the irreducible complexity of the content system. Which you choose should ultimately depend on the nature and type of complexity you are dealing with and the resource available to you to address that complexity. None of the structured writing domains are destinations, none are desirable in themselves, they are merely means to an end, and that end is a content system in which all of the complexity of content creation is handled by a person or algorithm with the appropriate skills, time, and resources to handle it.</p>
</section>
<section>
<title>Select tools</title>
<p>Once you have decided how you want to distribute complexity in your content system, you choose the languages, systems, and tools that allow you to implement that partitioning most efficiently. This may be a recursive process, since tools introduce complexity of their own which must be appropriately partitioned and distributed to make sure the tool does not introduce unhandled complexity into the system. As you begin to map tools into the system, pause to consider how the complexity that tool introduces will be handled. This may require changing other procedures or introducing other tools. If the tools introduces too much downstream complexity, or the complexity it introduces it hard to handle, you might need to consider a different tool, or even a different strategy for distributing complexity across your content system.</p>
<p>It is a simple fact of life that as you move content from the media domain towards the document and subject domains, the number of available off-the-shelf tools become fewer and the need to configure or extend those tools to get the result you need becomes greater. The reason for this is simple. The further you move your content towards the subject domain, the more you are relying on specific context-dependent algorithms to move it back to the media domain for publishing.</p>
<p>This is, after all, the point of the exercise. It is by moving functions from people to algorithms that we make sure that all of the complexity of the content system is handled appropriately and efficiently. The idea is to produce better content in less time and at less cost, and that is accomplished by handing parts of the work over to algorithms. And the further you go along the continuum from media domain to subject domain, the more particular the algorithms become to you, your organization, your audience, and your subject matter. Thus you have to become more engaged with the design of algorithms and the structures they require.</p>
<p>The need to take more responsibility for structures and algorithms is not a downside of adopting more structure, therefore. It is what you are aiming for: the transfer of effort and complexity from humans to algorithms, which means the transfer of complexity to those who write algorithms. The need to employ people to write and maintain those algorithms is not a drawback. Rather, it is the desire to transfer parts of your content system complexity to these people that drives your adoption of structured writing practices.</p>
<p>This is not something that should be taken lightly. It is the point of the exercise, and therefore something that needs to be taken seriously and approached deliberately. The development of this capability within your organization is actually far more important than your choice of tools or even domains. Understanding the capability you need to add to the organization comes back again to how you decide to partition the complexity of your system. Remember, the goal is to partition and direct complexity so that every part of that complexity is handled by a person or algorithm with the skills, time, and resources to handle it. Once you decide what complexity you want to partition and direct away from your writers, you know what you are expecting your information architects and content engineers to handle. Quite simply, then, you are looking for people with the skills to handle that complexity, and you need to give them the time and resources they need apply their skills to the complexity you have assigned to them. Since different organizations will face different levels of complexity and will partition and distribute it differently, the definition of those roles, and their qualifications, will different in different organizations.</p>
</section>
<section>
<title>Count the costs and savings</title>
<p>Most of what is written about structured writing focuses on cost savings, with the biggest arguments in its favor being focused on saving from content reuse and translation. I have chosen instead to focus this book on the management of complexity. The focus on cost reduction, while it makes for an easy sell to those who must ultimately fund any structured writing project, tends to lead to a focus on one particular cost in the system, and the systems introduced to reduce that cost sometimes introduce complexity into the system that eats up all of the anticipated savings while damaging the quality of the output.</p>
<p>A focus on cost reduction, too, carries with it an implicitly admission that you can’t think of ways to enhance the value of what you do – increasing value trumps reducing costs, and it has more upside. A focus on complexity, on the other hand, addresses both cost and quality at the same time. Unhandled complexity, or complexity handled by a person or process without the skills or resources to handle it properly, not only reduce quality, it also costs money. You may not be able to produce a neat (and misleading) spreadsheet that equates content reused with dollars saved, but a focus on comprehensive management of complexity can yield cost saving in all kinds of places, while also enhancing value.</p>
<p>The economics of this decision are clearly complex. You may decide that the cost of creating and maintaining the most appropriate algorithms and structures in not worth the cost or quality improvements they promise. But hopefully that decision can be made with a full appreciation of the benefits that those algorithms are capable of delivering. But whatever you decide, make sure you understand how complexity is being distributed in the systems that you implement. Make sure that the people you are distributing complexity to have the skills, time, and resources to handle it, and be conscious of the effect it will have on their productivity and the reliability of their work.</p>
<p>Structured writing is a tool for managing the complexity of your content system and making sure all of that complexity gets handled by people with the right skills and resources deal with it, so that it does not fall through to the reader. Getting there may require introducing new skills into your team. Don’t regard bringing in those skills as a downside of structured writing. Instead, look at the introduction of those skills are the method you are using to better handle the complexity of content creation. Look at structured writing simply are the technique you use to partition and transfer the complexity around your system so that everyone on the team can do their jobs better.</p>
</section>
</chapter>
